<div align="center">
  <h1>ü§ñ Curso de IA Generativa y Modelos de Lenguaje Grandes (LLMs)</h1>
  <p align="center">
    üê¶ <a href="https://twitter.com/nicolasmetallo">twitter</a> ‚Ä¢ 
    üíª <a href="https://www.machinelearnear.com/">web</a> ‚Ä¢ 
    üìπ <a href="https://www.youtube.com/@machinelearnear">youtube</a> ‚Ä¢ 
    üíª <a href="https://github.com/mlabonne/llm-course">repo original de @mlabonne</a>
  </p>
</div>
<br/>

>[!NOTE]  
>todo este laburo se basa en el [repo de @mlabonne](https://github.com/mlabonne/llm-course), **vayan a meterle una ‚≠ê ya mismo!**

Este curso de IA generativa y LLMs va a estar dividido en 3 partes:

1. üß© **Fundamentos de IA** cubre conocimientos esenciales sobre matem√°ticas, Python y redes neuronales.
2. üßë‚Äçüî¨ **Cientifico/a de LLMs** se enfoca en construir los mejores LLMs posibles usando las t√©cnicas m√°s recientes.
3. üë∑ **Ingeniero/a de LLMs** se concentra en crear aplicaciones basadas en LLM y desplegarlas.

## üìπ Videos

Una lista de algunos videos que hice que tocan varios de estos temas

| Titulo | Link |
|----------|-------------|
| C√≥mo es que funciona realmente Stable Diffusion? (Guia ilustrada paso a paso) | https://www.youtube.com/watch?v=00NV4EXcpLQ&ab_channel=machinelearnear |
| Como crear ChatGPT desde 0 explicado | https://www.youtube.com/watch?v=4uXeflZ8q8w&ab_channel=machinelearnear |
| Habilidades emergentes de GPT-3.5 | https://www.youtube.com/watch?v=TYFy0wZpJuY&ab_channel=machinelearnear |
| Reinforcement Learning from Human Feedback | https://www.youtube.com/watch?v=tzPuVAJ3XoI&ab_channel=machinelearnear |
| In-Context Learning & Gradient Descent | https://www.youtube.com/watch?v=TMYpH8wsGFU&ab_channel=machinelearnear |
| Que hace que un agente de di√°logo sea √∫til? | https://www.youtube.com/watch?v=DRf4j0EpYuQ&ab_channel=machinelearnear |
| "Estado de GPT" por Andrej Karpathy | https://www.youtube.com/watch?v=aqv6Sd67R7M&ab_channel=machinelearnear |
| Como las empresas crean aplicaciones con LLMs | https://www.youtube.com/watch?v=7YDxI66fySk&ab_channel=machinelearnear |
| Tutorial para hacer una aplicaci√≥n con GPT4, LangChain, Whisper, y otros | https://www.youtube.com/watch?v=1Rpn4lrshlo&ab_channel=machinelearnear |
| Ingenieria de Prompts (Octubre 2023) | https://www.youtube.com/watch?v=21pUaHVlHaQ&ab_channel=machinelearnear |

## üìù Notebooks

Una lista de notebooks y art√≠culos relacionados con modelos de lenguaje grandes.

| Titulo | Descripci√≥n | Link |
|----------|-------------|----------|
| üßê LLM AutoEval | Eval√∫a autom√°ticamente tus LLMs usando RunPod | <img src="img/colab.svg" alt="Abrir en Colab"> |
| ü•± LazyMergekit | Fusiona modelos f√°cilmente usando mergekit en un clic. | <img src="img/colab.svg" alt="Abrir en Colab"> |
| ‚ö° AutoGGUF | Cuantiza LLMs en formato GGUF en un clic. | <img src="img/colab.svg" alt="Abrir en Colab"> |
| üå≥ √Årbol Geneal√≥gico de Modelos | Visualiza el √°rbol geneal√≥gico de modelos fusionados. | <img src="img/colab.svg" alt="Abrir en Colab"> |

### Herramientas

| Cuaderno | Descripci√≥n | Cuaderno |
|----------|-------------|----------|
| üßê LLM AutoEval | Eval√∫a autom√°ticamente tus LLMs usando RunPod | <img src="img/colab.svg" alt="Abrir en Colab"> |
| ü•± LazyMergekit | Fusiona modelos f√°cilmente usando mergekit en un clic. | <img src="img/colab.svg" alt="Abrir en Colab"> |
| ‚ö° AutoGGUF | Cuantiza LLMs en formato GGUF en un clic. | <img src="img/colab.svg" alt="Abrir en Colab"> |
| üå≥ √Årbol Geneal√≥gico de Modelos | Visualiza el √°rbol geneal√≥gico de modelos fusionados. | <img src="img/colab.svg" alt="Abrir en Colab"> |

### Afinamiento

| Cuaderno | Descripci√≥n | Art√≠culo | Cuaderno |
|---------------------------------------|-------------------------------------------------------------------------|---------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------|
| Afinar Llama 2 en Google Colab | Gu√≠a paso a paso para afinar tu primer modelo Llama 2. | [Art√≠culo](https://mlabonne.github.io/blog/posts/Fine_Tune_Your_Own_Llama_2_Model_in_a_Colab_Notebook.html) | <img src="img/colab.svg" alt="Abrir en Colab"> |
| Afinar LLMs con Axolotl | Gu√≠a de principio a fin para la herramienta de vanguardia para afinamiento. | [Art√≠culo](https://mlabonne.github.io/blog/posts/A_Beginners_Guide_to_LLM_Finetuning.html) | <img src="img/colab.svg" alt="Abrir en Colab"> |
| Afinar Mistral-7b con DPO | Mejora el rendimiento de modelos afinados supervisados con DPO. | [Art√≠culo](https://medium.com/towards-data-science/fine-tune-a-mistral-7b-model-with-direct-preference-optimization-708042745aac) | <img src="img/colab.svg" alt="Abrir en Colab"> |

### Cuantizaci√≥n

| Cuaderno | Descripci√≥n | Art√≠culo | Cuaderno |
|---------------------------------------|-------------------------------------------------------------------------|---------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------|
| 1. Introducci√≥n a la Cuantizaci√≥n | Optimizaci√≥n de modelo de lenguaje grande usando cuantizaci√≥n de 8 bits. | [Art√≠culo](https://mlabonne.github.io/blog/posts/Introduction_to_Weight_Quantization.html) | <img src="img/colab.svg" alt="Abrir en Colab"> |
| 2. Cuantizaci√≥n de 4 bits usando GPTQ | Cuantiza tus propios LLMs de c√≥digo abierto para correrlos en hardware de consumidor. | [Art√≠culo](https://mlabonne.github.io/blog/4bit_quantization/) | <img src="img/colab.svg" alt="Abrir en Colab"> |
| 3. Cuantizaci√≥n con GGUF y llama.cpp | Cuantiza modelos Llama 2 con llama.cpp y sube versiones GGUF al HF Hub. | [Art√≠culo](https://mlabonne.github.io/blog/posts/Quantize_Llama_2_models_using_ggml.html) | <img src="img/colab.svg" alt="Abrir en Colab"> |
| 4. ExLlamaV2: La Biblioteca M√°s R√°pida para Correr LLMs | Cuantiza y corre modelos EXL2 y s√∫belos al HF Hub. | [Art√≠culo](https://mlabonne.github.io/blog/posts/ExLlamaV2_The_Fastest_Library_to_Run%C2%A0LLMs.html) | <img src="img/colab.svg"alt="Abrir en Colab"> |

### Otros

| Cuaderno | Descripci√≥n | Art√≠culo | Cuaderno |
|---------------------------------------|-------------------------------------------------------------------------|---------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------|
| Estrategias de Decodificaci√≥n en Modelos de Lenguaje Grandes | Una gu√≠a para la generaci√≥n de texto desde la b√∫squeda por haz hasta el muestreo de n√∫cleo | [Art√≠culo](https://mlabonne.github.io/blog/posts/2022-06-07-Decoding_strategies.html) | <img src="img/colab.svg" alt="Abrir en Colab"> |
| Visualizando el Paisaje de P√©rdida de GPT-2 | Gr√°fico 3D del paisaje de p√©rdida basado en perturbaciones de peso. | [Tweet](https://twitter.com/maximelabonne/status/1667618081844219904) | <img src="img/colab.svg" alt="Abrir en Colab"> |
| Mejorar ChatGPT con Grafos de Conocimiento | Ampl√≠a las respuestas de ChatGPT con grafos de conocimiento. | [Art√≠culo](https://mlabonne.github.io/blog/posts/Article_Improve_ChatGPT_with_Knowledge_Graphs.html) | <img src="img/colab.svg" alt="Abrir en Colab"> |
| Fusionar LLMs con mergekit | Crea tus propios modelos f√°cilmente, ¬°no se necesita GPU! | [Art√≠culo](https://towardsdatascience.com/merge-large-language-models-with-mergekit-2118fb392b54) | <img src="img/colab.svg" alt="Abrir en Colab"> |

## üß© Fundamentos de IA

### 1. Matem√°ticas para Aprendizaje Autom√°tico

Antes de dominar el aprendizaje autom√°tico, es importante entender los conceptos matem√°ticos fundamentales que impulsan estos algoritmos.

- **√Ålgebra Lineal**: Esto es crucial para entender muchos algoritmos, especialmente aquellos usados en aprendizaje profundo. Conceptos clave incluyen vectores, matrices, determinantes, valores y vectores propios, espacios vectoriales y transformaciones lineales.
- **C√°lculo**: Muchos algoritmos de aprendizaje autom√°tico involucran la optimizaci√≥n de funciones continuas, lo que requiere un entendimiento de derivadas, integrales, l√≠mites y series. El c√°lculo multivariable y el concepto de gradientes tambi√©n son importantes.
- **Probabilidad y Estad√≠stica**: Estos son cruciales para entender c√≥mo los modelos aprenden de datos y hacen predicciones. Conceptos clave incluyen teor√≠a de probabilidad, variables aleatorias, distribuciones de probabilidad, expectativas, varianza, covarianza, correlaci√≥n, pruebas de hip√≥tesis, intervalos de confianza, estimaci√≥n de m√°xima verosimilitud e inferencia Bayesiana.

üìö Recursos:

- [3Blue1Brown - La Esencia del √Ålgebra Lineal](https://www.youtube.com/watch?v=fNk_zzaMoSs&list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab): Serie de videos que proporcionan una intuici√≥n geom√©trica de estos conceptos.
- [StatQuest con Josh Starmer - Fundamentos de Estad√≠stica](https://www.youtube.com/watch?v=qBigTkBLU6g&list=PLblh5JKOoLUK0FLuzwntyYI10UQFUhsY9): Ofrece explicaciones simples y claras para muchos conceptos estad√≠sticos.
- [Intuici√≥n AP de Estad√≠sticas por Ms Aerin](https://automata88.medium.com/list/cacc224d5e7d): Lista de art√≠culos en Medium que proporcionan la intuici√≥n detr√°s de cada distribuci√≥n de probabilidad.
- [√Ålgebra Lineal Inmersiva](https://immersivemath.com/ila/learnmore.html): Otra interpretaci√≥n visual del √°lgebra lineal.
- [Khan Academy - √Ålgebra Lineal](https://www.khanacademy.org/math/linear-algebra): Genial para principiantes ya que explica los conceptos de manera muy intuitiva.
- [Khan Academy - C√°lculo](https://www.khanacademy.org/math/calculus-1): Un curso interactivo que cubre todos los fundamentos del c√°lculo.
- [Khan Academy - Probabilidad y Estad√≠stica](https://www.khanacademy.org/math/statistics-probability): Presenta el material de forma f√°cil de entender.

---

### 2. Python para Aprendizaje Autom√°tico

Python es un lenguaje de programaci√≥n poderoso y flexible que es particularmente bueno para el aprendizaje autom√°tico, gracias a su legibilidad, consistencia y el robusto ecosistema de bibliotecas de ciencia de datos.

- **Fundamentos de Python**: Programar en Python requiere un buen entendimiento de la sintaxis b√°sica, tipos de datos, manejo de errores y programaci√≥n orientada a objetos.
- **Bibliotecas de Ciencia de Datos**: Incluye familiaridad con NumPy para operaciones num√©ricas, Pandas para manipulaci√≥n y an√°lisis de datos, Matplotlib y Seaborn para visualizaci√≥n de datos.
- **Preprocesamiento de Datos**: Esto involucra escalado y normalizaci√≥n de caracter√≠sticas, manejo de datos faltantes, detecci√≥n de valores at√≠picos, codificaci√≥n de datos categ√≥ricos y divisi√≥n de datos en conjuntos de entrenamiento, validaci√≥n y prueba.
- **Bibliotecas de Aprendizaje Autom√°tico**: Proficiencia con Scikit-learn, una biblioteca que proporciona una amplia selecci√≥n de algoritmos de aprendizaje supervisado y no supervisado, es vital. Entender c√≥mo implementar algoritmos como regresi√≥n lineal, regresi√≥n log√≠stica, √°rboles de decisi√≥n, bosques aleatorios, vecinos m√°s cercanos (K-NN) y agrupamiento por K-medias es importante. T√©cnicas de reducci√≥n de dimensionalidad como PCA y t-SNE tambi√©n son √∫tiles para visualizar datos de alta dimensi√≥n.

üìö Recursos:

- [Real Python](https://realpython.com/): Un recurso comprensivo con art√≠culos y tutoriales tanto para conceptos de Python principiantes como avanzados.
- [freeCodeCamp - Aprende Python](https://www.youtube.com/watch?v=rfscVS0vtbw): Video largo que proporciona una introducci√≥n completa a todos los conceptos fundamentales en Python.
- [Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/): Libro digital gratuito que es un gran recurso para aprender pandas, NumPy, Matplotlib y Seaborn.
- [freeCodeCamp - Aprendizaje Autom√°tico para Todos](https://youtu.be/i_LwzRVP7bg): Introducci√≥n pr√°ctica a diferentes algoritmos de aprendizaje autom√°tico para principiantes.
- [Udacity - Introducci√≥n al Aprendizaje Autom√°tico](https://www.udacity.com/course/intro-to-machine-learning--ud120): Curso gratuito que cubre PCA y varios otros conceptos de aprendizaje autom√°tico.

---

### 3. Redes Neuronales

Las redes neuronales son una parte fundamental de muchos modelos de aprendizaje autom√°tico, particularmente en el √°mbito del aprendizaje profundo. Para utilizarlas efectivamente, es esencial tener un entendimiento comprensivo de su dise√±o y mec√°nicas.

- **Fundamentos**: Esto incluye entender la estructura de una red neuronal como capas, pesos, sesgos y funciones de activaci√≥n (sigmoide, tanh, ReLU, etc.)
- **Entrenamiento y Optimizaci√≥n**: Familiar√≠zate con la retropropagaci√≥n y diferentes tipos de funciones de p√©rdida, como Error Cuadr√°tico Medio (MSE) y Entrop√≠a Cruzada. Entiende varios algoritmos de optimizaci√≥n como Descenso de Gradiente, Descenso de Gradiente Estoc√°stico, RMSprop y Adam.
- **Sobreajuste**: Entender el concepto de sobreajuste (donde un modelo rinde bien en datos de entrenamiento pero pobremente en datos no vistos) y aprender varias t√©cnicas de regularizaci√≥n (abandono, regularizaci√≥n L1/L2, detenci√≥n temprana, aumento de datos) para prevenirlo.
- **Implementar un Perceptr√≥n Multicapa (MLP)**: Construye un MLP, tambi√©n conocido como una red completamente conectada, usando PyTorch.

üìö Recursos:

- [3Blue1Brown - Pero, ¬øqu√© es una red neuronal?](https://www.youtube.com/watch?v=aircAruvnKk): Este video ofrece una explicaci√≥n intuitiva de las redes neuronales y su funcionamiento interno.
- [freeCodeCamp - Curso Acelerado de Aprendizaje Profundo](https://www.youtube.com/watch?v=VyWAvY2CF9c): Este video introduce de manera eficiente todos los conceptos m√°s importantes en aprendizaje profundo.
- [Fast.ai - Aprendizaje Profundo Pr√°ctico](https://course.fast.ai/): Curso gratuito dise√±ado para personas con experiencia en programaci√≥n que quieran aprender sobre aprendizaje profundo.
- [Patrick Loeber - Tutoriales de PyTorch](https://www.youtube.com/playlist?list=PLqnslRFeH2UrcDBWF5mfPGpqQDSta6VK4): Serie de videos para principiantes completos para aprender sobre PyTorch.

---

### 4. Procesamiento de Lenguaje Natural (NLP)

NLP es una rama fascinante de la inteligencia artificial que cierra la brecha entre el lenguaje humano y la comprensi√≥n de las m√°quinas. Desde el procesamiento de texto simple hasta la comprensi√≥n de matices ling√º√≠sticos, NLP juega un papel crucial en muchas aplicaciones como traducci√≥n, an√°lisis de sentimientos, chatbots y mucho m√°s.

- **Preprocesamiento de Texto**: Aprende varios pasos de preprocesamiento de texto como tokenizaci√≥n (dividir texto en palabras o frases), stemming (reducir palabras a su forma ra√≠z), lematizaci√≥n (similar al stemming pero considera el contexto), eliminaci√≥n de palabras vac√≠as, etc.
- **T√©cnicas de Extracci√≥n de Caracter√≠sticas**: Familiar√≠zate con t√©cnicas para convertir datos de texto en un formato que pueda ser entendido por algoritmos de aprendizaje autom√°tico. Los m√©todos clave incluyen Bolsa de palabras (BoW), Frecuencia de T√©rmino - Inversa de Frecuencia de Documentos (TF-IDF) y n-gramas.
- **Embeddings de Palabras**: Los embeddings de palabras son un tipo de representaci√≥n de palabras que permite que palabras con significados similares tengan representaciones similares. Los m√©todos clave incluyen Word2Vec, GloVe y FastText.
- **Redes Neuronales Recurrentes (RNNs)**: Entiende el funcionamiento de RNNs, un tipo de red neuronal dise√±ada para trabajar con datos secuenciales. Explora LSTMs y GRUs, dos variantes de RNN que son capaces de aprender dependencias a largo plazo.

üìö Recursos:

- [RealPython - NLP con spaCy en Python](https://realpython.com/natural-language-processing-spacy-python/): Gu√≠a exhaustiva sobre la biblioteca spaCy para tareas de NLP en Python.
- [Kaggle - Gu√≠a de NLP](https://www.kaggle.com/learn-guide/natural-language-processing): Unos cuadernos y recursos para una explicaci√≥n pr√°ctica de NLP en Python.
- [Jay Alammar - La Ilustraci√≥n Word2Vec](https://jalammar.github.io/illustrated-word2vec/): Una buena referencia para entender la famosa arquitectura Word2Vec.
- [Jake Tae - PyTorch RNN desde Cero](https://jaketae.github.io/study/pytorch-rnn/): Implementaci√≥n pr√°ctica y simple de modelos RNN, LSTM y GRU en PyTorch.
- [Blog de Colah - Entendiendo las Redes LSTM](https://colah.github.io/posts/2015-08-Understanding-LSTMs/): Un art√≠culo m√°s te√≥rico sobre la red LSTM.

## üßë‚Äçüî¨ El Cient√≠fico de LLM

Esta secci√≥n del curso se enfoca en aprender c√≥mo construir los mejores LLMs posibles usando las t√©cnicas m√°s recientes.

### 1. La arquitectura LLM

Aunque no es necesario un conocimiento profundo sobre la arquitectura Transformer, es importante tener un buen entendimiento de sus entradas (tokens) y salidas (logits). El mecanismo de atenci√≥n b√°sico es otro componente crucial para dominar, ya que se introducen versiones mejoradas m√°s adelante.

* **Vista de alto nivel**: Revisar la arquitectura Transformer de codificador-decodificador, y m√°s espec√≠ficamente la arquitectura GPT solo de decodificador, que se usa en todos los LLMs modernos.
* **Tokenizaci√≥n**: Entender c√≥mo convertir datos de texto crudo en un formato que el modelo pueda entender, lo que involucra dividir el texto en tokens (generalmente palabras o subpalabras).
* **Mecanismos de atenci√≥n**: Comprender la teor√≠a detr√°s de los mecanismos de atenci√≥n, incluyendo la autoatenci√≥n y la atenci√≥n de producto punto escalado, que permite al modelo enfocarse en diferentes partes de la entrada al producir una salida.
* **Generaci√≥n de texto**: Aprender sobre las diferentes maneras en que el modelo puede generar secuencias de salida. Las estrategias comunes incluyen la decodificaci√≥n √°vida, b√∫squeda por haz, muestreo top-k y muestreo de n√∫cleo.

üìö **Referencias**:
- [El Transformer Ilustrado](https://jalammar.github.io/illustrated-transformer/) por Jay Alammar: Una explicaci√≥n visual e intuitiva del modelo Transformer.
- [El GPT-2 Ilustrado](https://jalammar.github.io/illustrated-gpt2/) por Jay Alammar: M√°s importante que el art√≠culo anterior, se centra en la arquitectura GPT, muy similar a la de Llama.
- [Visualizaci√≥n LLM](https://bbycroft.net/llm) por Brendan Bycroft: Incre√≠ble visualizaci√≥n 3D de lo que sucede dentro de un LLM.
* [nanoGPT](https://www.youtube.com/watch?v=kCc8FmEb1nY) por Andrej Karpathy: Video de 2 horas en YouTube para reimplementar GPT desde cero (para programadores).
* [¬øAtenci√≥n? ¬°Atenci√≥n!](https://lilianweng.github.io/posts/2018-06-24-attention/) por Lilian Weng: Introduce la necesidad de atenci√≥n de una manera m√°s formal.
* [Estrategias de Decodificaci√≥n en LLMs](https://mlabonne.github.io/blog/posts/2023-06-07-Decoding_strategies.html): Proporciona c√≥digo y una introducci√≥n visual a las diferentes estrategias de decodificaci√≥n para generar texto.

---
### 2. Construyendo un conjunto de datos de instrucciones

Aunque es f√°cil encontrar datos crudos de Wikipedia y otros sitios web, es dif√≠cil recolectar pares de instrucciones y respuestas en la naturaleza. Como en el aprendizaje autom√°tico tradicional, la calidad del conjunto de datos influir√° directamente en la calidad del modelo, lo que significa que podr√≠a ser el componente m√°s importante en el proceso de afinamiento.

* **Conjunto de datos tipo [Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html)**: Generar datos sint√©ticos desde cero con la API de OpenAI (GPT). Puedes especificar semillas y prompts del sistema para crear un conjunto de datos diverso.
* **T√©cnicas avanzadas**: Aprender c√≥mo mejorar conjuntos de datos existentes con [Evol-Instruct](https://arxiv.org/abs/2304.12244), c√≥mo generar datos sint√©ticos de alta calidad como en los papeles [Orca](https://arxiv.org/abs/2306.02707) y [phi-1](https://arxiv.org/abs/2306.11644).
* **Filtrado de datos**: T√©cnicas tradicionales que involucran regex, eliminaci√≥n de duplicados cercanos, enfoc√°ndose en respuestas con un alto n√∫mero de tokens, etc.
* **Plantillas de prompts**: No existe una manera est√°ndar verdadera de formatear instrucciones y respuestas, por lo que es importante saber sobre las diferentes plantillas de chat, como [ChatML](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/chatgpt?

tabs=python&pivots=programming-language-chat-ml), [Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html), etc.

üìö **Referencias**:
* [Preparando un Conjunto de Datos para Ajuste de Instrucciones](https://wandb.ai/capecape/alpaca_ft/reports/How-to-Fine-Tune-an-LLM-Part-1-Preparing-a-Dataset-for-Instruction-Tuning--Vmlldzo1NTcxNzE2) por Thomas Capelle: Exploraci√≥n de los conjuntos de datos Alpaca y Alpaca-GPT4 y c√≥mo formatearlos.
* [Generando un Conjunto de Datos de Instrucci√≥n Cl√≠nica](https://medium.com/mlearning-ai/generating-a-clinical-instruction-dataset-in-portuguese-with-langchain-and-gpt-4-6ee9abfa41ae) por Solano Todeschini: Tutorial sobre c√≥mo crear un conjunto de datos de instrucci√≥n sint√©tico usando GPT-4.
* [GPT 3.5 para clasificaci√≥n de noticias](https://medium.com/@kshitiz.sahay26/how-i-created-an-instruction-dataset-using-gpt-3-5-to-fine-tune-llama-2-for-news-classification-ed02fe41c81f) por Kshitiz Sahay: Uso de GPT 3.5 para crear un conjunto de datos de instrucci√≥n para afinar Llama 2 para clasificaci√≥n de noticias.
* [Creaci√≥n de conjunto de datos para afinamiento de LLM](https://colab.research.google.com/drive/1GH8PW9-zAe4cXEZyOIE-T9uHXblIldAg?usp=sharing): Cuaderno que contiene algunas t√©cnicas para filtrar un conjunto de datos y subir el resultado.
* [Plantilla de Chat](https://huggingface.co/blog/chat-templates) por Matthew Carrigan: P√°gina de Hugging Face sobre plantillas de prompts.

---
### 3. Preentrenamiento de modelos

El preentrenamiento es un proceso muy largo y costoso, por lo que no es el foco de este curso. Es bueno tener alg√∫n nivel de entendimiento sobre lo que sucede durante el preentrenamiento, pero la experiencia pr√°ctica no es requerida.

* **Pipeline de datos**: El preentrenamiento requiere enormes conjuntos de datos (por ejemplo, [Llama 2](https://arxiv.org/abs/2307.09288) fue entrenado en 2 billones de tokens) que necesitan ser filtrados, tokenizados y agrupados con un vocabulario predefinido.
* **Modelado de lenguaje causal**: Aprender la diferencia entre modelado de lenguaje causal y modelado de lenguaje enmascarado, as√≠ como la funci√≥n de p√©rdida utilizada en este caso. Para un preentrenamiento eficiente, aprender m√°s sobre [Megatron-LM](https://github.com/NVIDIA/Megatron-LM) o [gpt-neox](https://github.com/EleutherAI/gpt-neox).
* **Leyes de escalamiento**: Las [leyes de escalamiento](https://arxiv.org/pdf/2001.08361.pdf) describen el rendimiento esperado del modelo basado en el tama√±o del modelo, tama√±o del conjunto de datos y la cantidad de c√≥mputo usado para el entrenamiento.
* **Computaci√≥n de Alto Rendimiento**: Fuera del alcance aqu√≠, pero m√°s conocimiento sobre HPC es fundamental si est√°s planeando crear tu propio LLM desde cero (hardware, carga de trabajo distribuida, etc.).

üìö **Referencias**:
* [LLMDataHub](https://github.com/Zjh-819/LLMDataHub) por Junhao Zhao: Lista curada de conjuntos de datos para preentrenamiento, afinamiento y RLHF.
* [Entrenando un modelo de lenguaje causal desde cero](https://huggingface.co/learn/nlp-course/chapter7/6?fw=pt) por Hugging Face: Preentrena un modelo GPT-2 desde cero usando la biblioteca transformers.
* [TinyLlama](https://github.com/jzhang38/TinyLlama) por Zhang et al.: Consulta este proyecto para obtener un buen entendimiento de c√≥mo se entrena un modelo Llama desde cero.
* [Modelado de lenguaje causal](https://huggingface.co/docs/transformers/tasks/language_modeling) por Hugging Face: Explica la diferencia entre modelado de lenguaje causal y enmascarado y c√≥mo afinar r√°pidamente un modelo Distil

GPT-2.
* [Las salvajes implicaciones de Chinchilla](https://www.lesswrong.com/posts/6Fpvch8RR29qLEWNH/chinchilla-s-wild-implications) por nostalgebraist: Discute las leyes de escalamiento y explica lo que significan para los LLMs en general.
* [BLOOM](https://bigscience.notion.site/BLOOM-BigScience-176B-Model-ad073ca07cdf479398d5f95d88e218c4) por BigScience: P√°gina de Notion que describe c√≥mo se construy√≥ el modelo BLOOM, con mucha informaci√≥n √∫til sobre la parte de ingenier√≠a y los problemas que se encontraron.
* [Libreta de bit√°cora OPT-175](https://github.com/facebookresearch/metaseq/blob/main/projects/OPT/chronicles/OPT175B_Logbook.pdf) por Meta: Registros de investigaci√≥n que muestran lo que sali√≥ mal y lo que sali√≥ bien. √ötil si planeas preentrenar un modelo de lenguaje grande (en este caso, 175B par√°metros).
* [LLM 360](https://www.llm360.ai/): Un marco para LLMs de c√≥digo abierto con c√≥digo de entrenamiento y preparaci√≥n de datos, datos, m√©tricas y modelos.

---
### 4. Afinamiento Supervisado

Los modelos preentrenados solo est√°n entrenados en una tarea de predicci√≥n del siguiente token, por lo que no son asistentes √∫tiles. SFT te permite ajustarlos para responder a instrucciones. Adem√°s, te permite afinar tu modelo en cualquier dato (privado, no visto por GPT-4, etc.) y usarlo sin tener que pagar por una API como la de OpenAI.

* **Afinamiento completo**: El afinamiento completo se refiere a entrenar todos los par√°metros en el modelo. No es una t√©cnica eficiente, pero produce resultados ligeramente mejores.
* [**LoRA**](https://arxiv.org/abs/2106.09685): Una t√©cnica de afinamiento eficiente en par√°metros (PEFT) basada en adaptadores de rango bajo. En lugar de entrenar todos los par√°metros, solo entrenamos estos adaptadores.
* [**QLoRA**](https://arxiv.org/abs/2305.14314): Otra PEFT basada en LoRA, que tambi√©n cuantiza los pesos del modelo en 4 bits e introduce optimizadores paginados para manejar picos de memoria. Comb√≠nalo con [Unsloth](https://github.com/unslothai/unsloth) para correrlo eficientemente en un cuaderno Colab gratuito.
* **[Axolotl](https://github.com/OpenAccess-AI-Collective/axolotl)**: Una herramienta de afinamiento poderosa y f√°cil de usar que se utiliza en muchos modelos de c√≥digo abierto de vanguardia.
* [**DeepSpeed**](https://www.deepspeed.ai/): Preentrenamiento y afinamiento eficientes de LLMs para configuraciones multi-GPU y multi-nodo (implementado en Axolotl).

üìö **Referencias**:
* [La Gu√≠a de Entrenamiento de LLM para Novatos](https://rentry.org/llm-training) por Alpin: Visi√≥n general de los principales conceptos y par√°metros a considerar al afinar LLMs.
* [Perspectivas de LoRA](https://lightning.ai/pages/community/lora-insights/) por Sebastian Raschka: Perspectivas pr√°cticas sobre LoRA y c√≥mo seleccionar los mejores par√°metros.
* [Afine Tu Propio Modelo Llama 2](https://mlabonne.github.io/blog/posts/Fine_Tune_Your_Own_Llama_2_Model_in_a_Colab_Notebook.html): Tutorial pr√°ctico sobre c√≥mo afinar un modelo Llama 2 usando bibliotecas de Hugging Face.
* [Rellenando Modelos de Lenguaje Grandes](https://towardsdatascience.com/padding-large-language-models-examples-with-llama-2-199fb10df8ff) por Benjamin Marie: Mejores pr√°cticas para rellenar ejemplos de entrenamiento para LLMs causales
* [Una Gu√≠a para Principiantes en Afinamiento de LLM](https://mlabonne.github.io/blog/posts/A_Beginners_Guide_to_LLM_Finetuning.html): Tutorial sobre c√≥mo afinar un modelo CodeLlama usando Axolotl.

---
### 5. Aprendizaje por Refuerzo a partir de Retroalimentaci√≥n Humana

Despu√©s del afinamiento supervisado, el ARRH es un paso usado para alinear las respuestas del LLM con las expectativas humanas. La idea es aprender preferencias a partir de retroalimentaci√≥n humana (o artificial), que se puede usar para reducir sesgos, censurar modelos, o hacerlos actuar de una manera m√°s √∫til. Es m√°s complejo que el SFT y a menudo se ve como opcional.

* **Conjuntos de datos de preferencia**: Estos conjuntos t√≠picamente contienen varias respuestas con alg√∫n tipo de clasificaci√≥n, lo que los hace m√°s dif√≠ciles de producir que los conjuntos de instrucciones.
* [**Optimizaci√≥n de Pol√≠tica Proximal**](https://arxiv.org/abs/1707.06347): Este algoritmo aprovecha un modelo de recompensa que predice si un texto dado est√° altamente clasificado por humanos. Esta predicci√≥n se usa luego para optimizar el modelo SFT con una penalizaci√≥n basada en divergencia KL.
* **[Optimizaci√≥n de Preferencia Directa](https://arxiv.org/abs/2305.18290)**: DPO simplifica el proceso al reformularlo como un problema de clasificaci√≥n. Usa un modelo de referencia en lugar de un modelo de recompensa (no necesita entrenamiento) y solo requiere un hiperpar√°metro, lo que lo hace m√°s estable y eficiente.

üìö **Referencias**:
* [Una Introducci√≥n al Entrenamiento de LLMs usando ARRH](https://wandb.ai/ayush-thakur/Intro-RLAIF/reports/An-Introduction-to-Training-LLMs-Using-Reinforcement-Learning-From-Human-Feedback-RLHF---VmlldzozMzYyNjcy) por Ayush Thakur: Explica por qu√© el ARRH es deseable para reducir el sesgo y aumentar el rendimiento en LLMs.
* [Ilustraci√≥n ARRH](https://huggingface.co/blog/rlhf) por Hugging Face: Introducci√≥n al ARRH con entrenamiento de modelo de recompensa y afinamiento con aprendizaje por refuerzo.
* [StackLLaMA](https://huggingface.co/blog/stackllama) por Hugging Face: Tutorial para alinear eficientemente un modelo LLaMA con ARRH usando la biblioteca de transformers.
* [Entrenamiento de LLM: ARRH y Sus Alternativas](https://substack.com/profile/27393275-sebastian-raschka-phd) por Sebastian Rashcka: Visi√≥n general del proceso de ARRH y alternativas como RLAIF.
* [Afinar Mistral-7b con DPO](https://huggingface.co/blog/dpo-trl): Tutorial para afinar un modelo Mistral-7b con DPO y reproducir [NeuralHermes-2.5](https://huggingface.co/mlabonne/NeuralHermes-2.5-Mistral-7B).

---
### 6. Evaluaci√≥n

Evaluar LLMs es una parte subestimada del pipeline, que consume tiempo y es moderadamente confiable. Tu tarea espec√≠fica deber√≠a dictar qu√© quieres evaluar, pero siempre recuerda la ley de Goodhart: "Cuando una medida se convierte en un objetivo, deja de ser una buena medida."

* **M√©tricas tradicionales**: M√©tricas como la perplejidad y el puntaje BLEU no son tan populares como lo eran porque est√°n defectuosas en la mayor√≠a de los contextos. A√∫n es importante entenderlas y cu√°ndo pueden ser aplicadas.
* **Benchmarks generales**: Basados en el [Language Model Evaluation Harness](https://github.com/EleutherAI/lm-evaluation-harness), el [Open LLM Leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard) es el principal benchmark para LLMs de prop√≥sito general (como ChatGPT). Hay otros benchmarks populares como [BigBench](https://github.com/google/BIG-bench), [MT-Bench](https://arxiv.org/abs/2306.05685), etc.
* **Benchmarks espec√≠ficos de tareas**: Tareas como la summarizaci√≥n, traducci√≥n y respuesta a preguntas tienen benchmarks dedicados, m√©tricas e incluso subdominios (m√©dico, financiero, etc.), como [PubMedQA](https://pubmedqa.github.io/) para respuesta a preguntas biom√©dicas.
* **Evaluaci√≥n humana**: La evaluaci√≥n m√°s confiable es la tasa de aceptaci√≥n por parte de los usuarios o comparaciones hechas por humanos. Si quieres saber si un modelo rinde bien, la forma m√°s simple pero segura es usarlo t√∫ mismo.

üìö **Referencias**:
* [Perplejidad de modelos de longitud fija](https://huggingface.co/docs/transformers/perplexity) por Hugging Face: Visi√≥n general de la perplejidad con c√≥digo para implementarlo con la biblioteca de transformers.
* [BLEU a tu propio riesgo](https://towardsdatascience.com/evaluating-text-output-in-nlp-bleu-at-your-own-risk-e8609665a213) por Rachael Tatman: Visi√≥n general del puntaje BLEU y sus muchos problemas con ejemplos.
* [Una Encuesta sobre la Evaluaci√≥n de LLMs](https://arxiv.org/abs/2307.03109) por Chang et al.: Documento comprensivo sobre qu√© evaluar, d√≥nde evaluar y c√≥mo evaluar.
* [Chatbot Arena Leaderboard](https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard) por lmsys: Clasificaci√≥n Elo de LLMs de prop√≥sito general, basada en comparaciones hechas por humanos.

---
### 7. Cuantizaci√≥n

La cuantizaci√≥n es el proceso de convertir los pesos (y activaciones) de un modelo usando una precisi√≥n menor. Por ejemplo, los pesos almacenados usando 16 bits pueden ser convertidos en una representaci√≥n de 4 bits. Esta t√©cnica se ha vuelto cada vez m√°s importante para reducir los costos computacionales y de memoria asociados con los LLMs.

* **T√©cnicas base**: Aprende los diferentes niveles de precisi√≥n (FP32, FP16, INT8, etc.) y c√≥mo realizar cuantizaci√≥n na√≠f con t√©cnicas de absmax y punto cero.
* **GGUF y llama.cpp**: Originalmente dise√±ado para correr en CPUs, [llama.cpp](https://github.com/ggerganov/llama.cpp) y el formato GGUF se han vuelto las herramientas m√°s populares para correr LLMs en hardware de grado consumidor.
* **GPTQ y EXL2**: [GPTQ](https://arxiv.org/abs/2210.17323) y, m√°s espec√≠ficamente, el formato [EXL2](https://github.com/turboderp/exllamav2) ofrecen una velocidad incre√≠ble pero solo pueden correr en GPUs. Los modelos tambi√©n toman un largo tiempo en ser cuantizados.
* **AWQ**: Este nuevo formato es m√°s preciso que GPTQ (menor perplejidad) pero usa mucho m√°s VRAM y no necesariamente es m√°s r√°pido.

üìö **Referencias**:
* [Introducci√≥n a la cuantizaci√≥n](https://mlabonne.github.io/blog/posts/Introduction_to_Weight_Quantization.html): Visi√≥n general de la cuantizaci√≥n, cuantizaci√≥n absmax y punto cero, y LLM.int8() con c√≥digo.
* [Cuantiza modelos Llama con llama.cpp](https://mlabonne.github.io/blog/posts/Quantize_Llama_2_models_using_ggml.html): Tutorial sobre c√≥mo cuantizar un modelo Llama 2 usando llama.cpp y el formato GGUF.
* [Cuantizaci√≥n de LLM de 4 bits con GPTQ](https://mlabonne.github.io/blog/posts/Introduction_to_Weight_Quantization.html): Tutorial sobre c√≥mo cuantizar un LLM usando el algoritmo GPTQ con AutoGPTQ.
* [ExLlamaV2: La Biblioteca M√°s R√°pida para Correr LLMs](https://mlabonne.github.io/blog/posts/ExLlamaV2_The_Fastest_Library_to_Run%C2%A0LLMs.html): Gu√≠a sobre c√≥mo cuantizar un modelo Mistral usando el formato EXL2 y correrlo con la biblioteca ExLlamaV2.
* [Entendiendo la Cuantizaci√≥n de Pesos Consciente de Activaci√≥n](https://medium.com/friendliai/understanding-activation-aware-weight-quantization-awq-boosting-inference-serving-efficiency-in-10bb0faf63a8) por FriendliAI: Visi√≥n general de la t√©cnica AWQ y sus beneficios.

---
### 8. Nuevas Tendencias

* **Codificaciones posicionales**: Aprende c√≥mo los LLMs codifican posiciones, especialmente esquemas de codificaci√≥n posicional relativa como [RoPE](https://arxiv.org/abs/2104.09864). Implementa [YaRN](https://arxiv.org/abs/2309.00071) (multiplica la matriz de atenci√≥n por un factor de temperatura) o [ALiBi](https://arxiv.org/abs/2108.12409) (penalizaci√≥n de atenci√≥n basada en la distancia de tokens) para extender la longitud del contexto.
* **Fusi√≥n de modelos**: Fusionar modelos entrenados se ha vuelto una manera popular de crear modelos performantes sin ning√∫n afinamiento. La popular biblioteca [mergekit](https://github.com/cg123/mergekit) implementa los m√©todos de fusi√≥n m√°s populares, como SLERP, [DARE](https://arxiv.org/abs/2311.03099), y [TIES](https://arxiv.org/abs/2311.03099).
* **Mezcla de Expertos**: [Mixtral](https://arxiv.org/abs/2401.04088) repopulariz√≥ la arquitectura MoE gracias a su excelente rendimiento. Paralelamente, un tipo de frankenMoE emergi√≥ en la comunidad OSS fusionando modelos como [Phixtral](https://huggingface.co/mlabonne/phixtral-2x2_8), que es una opci√≥n m√°s econ√≥mica y performante.
* **Modelos multimodales**: Estos modelos (como [CLIP](https://openai.com/research/clip), [Stable Diffusion](https://stability.ai/stable-image), o [LLaVA](https://llava-vl.github.io/)) procesan m√∫ltiples tipos de entradas (texto, im√°genes, audio, etc.) con un espacio de incrustaci√≥n unificado, lo que desbloquea aplicaciones poderosas como texto-a-imagen.

üìö **Referencias**:
* [Extendiendo el RoPE](https://blog.eleuther.ai/yarn/) por EleutherAI: Art√≠culo que resume las diferentes t√©cnicas de codificaci√≥n de posici√≥n.
* [Entendiendo YaRN](https://medium.com/@rcrajatchawla/understanding-yarn-extending-context-window-of-llms-3f21e3522465) por Rajat Chawla: Introducci√≥n a YaRN.
* [Fusionar LLMs con mergekit](https://mlabonne.github.io/blog/posts/2024-01-08_Merge_LLMs_with_mergekit.html): Tutorial sobre fusi√≥n de modelos usando mergekit.
* [Mezcla de Expertos Explicada](https://huggingface.co/blog/moe) por Hugging Face: Gu√≠a exhaustiva sobre MoEs y c√≥mo funcionan.
* [Modelos Multimodales Grandes](https://huyenchip.com/2023/10/10/multimodal.html) por Chip Huyen: Visi√≥n general de sistemas multimodales y la historia reciente de este campo.

## üë∑ El Ingeniero de LLM

Esta secci√≥n del curso se enfoca en aprender c√≥mo construir aplicaciones potenciadas por LLM que puedan usarse en producci√≥n, con un enfoque en aumentar modelos y desplegarlos.

![](img/roadmap_engineer.png)

### 1. Ejecutando LLMs

Ejecutar LLMs puede ser dif√≠cil debido a los altos requisitos de hardware. Dependiendo de tu caso de uso, podr√≠as querer simplemente consumir un modelo a trav√©s de una API (como GPT-4) o ejecutarlo localmente. En cualquier caso, t√©cnicas adicionales de prompting y gu√≠a pueden mejorar y restringir la salida para tus aplicaciones.

* **APIs de LLM**: Las APIs son una manera conveniente de desplegar LLMs. Este espacio est√° dividido entre LLMs privados ([OpenAI](https://platform.openai.com/), [Google](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/overview), [Anthropic](https://docs.anthropic.com/claude/reference/getting-started-with-the-api), [Cohere](https://docs.cohere.com/docs), etc.) y LLMs de c√≥digo abierto ([OpenRouter](https://openrouter.ai/), [Hugging Face](https://huggingface.co/inference-api), [Together AI](https://www.together.ai/), etc.).
* **LLMs de c√≥digo abierto**: El [Hugging Face Hub](https://huggingface.co/models) es un excelente lugar para encontrar LLMs. Puedes ejecutar algunos de ellos directamente en [Hugging Face Spaces](https://huggingface.co/spaces), o descargarlos y ejecutarlos localmente en aplicaciones como [LM Studio](https://lmstudio.ai/) o a trav√©s de la CLI con [llama.cpp](https://github.com/ggerganov/llama.cpp) o [Ollama](https://ollama.ai/).
* **Ingenier√≠a de prompts**: T√©cnicas comunes incluyen prompting de cero disparos, prompting de pocos disparos, cadena de pensamiento y ReAct. Funcionan mejor con modelos m√°s grandes, pero pueden adaptarse a modelos m√°s peque√±os.
* **Estructurando salidas**: Muchas tareas requieren una salida estructurada, como una plantilla estricta o un formato JSON. Bibliotecas como [LMQL](https://lmql.ai/), [Outlines](https://github.com/outlines-dev/outlines), [Guidance](https://github.com/guidance-ai/guidance), etc. pueden usarse para guiar la generaci√≥n y respetar una estructura dada.

üìö **Referencias**:
* [Ejecuta un LLM localmente con LM Studio](https://www.kdnuggets.com/run-an-llm-locally-with-lm-studio) por Nisha Arya: Gu√≠a corta sobre c√≥mo usar LM Studio.
* [Gu√≠a de ingenier√≠a de prompts](https://www.promptingguide.ai/) por DAIR.AI: Lista exhaustiva de t√©cnicas de prompts con ejemplos.
* [Outlines - Inicio r√°pido](https://outlines-dev.github.io/outlines/quickstart/): Lista de t√©cnicas de generaci√≥n guiada habilitadas por Outlines.
* [LMQL - Visi√≥n general](https://lmql.ai/docs/language/overview.html): Introducci√≥n al lenguaje LMQL.

---
### 2. Construyendo un Almacenamiento de Vectores

Crear un almacenamiento de vectores es el primer paso para construir una tuber√≠a de Generaci√≥n Aumentada por Recuperaci√≥n (RAG). Los documentos se cargan, se dividen y los fragmentos relevantes se usan para producir representaciones vectoriales (incrustaciones) que se almacenan para su uso futuro durante la inferencia.

* **Ingesta de documentos**: Los cargadores de documentos son envoltorios convenientes que pueden manejar muchos formatos: PDF, JSON, HTML, Markdown, etc. Tambi√©n pueden recuperar datos directamente de algunas bases de datos y APIs (GitHub, Reddit, Google Drive, etc.).
* **Divisi√≥n de documentos**: Los divisores de texto descomponen los documentos en fragmentos m√°s peque√±os, sem√°nticamente significativos. En lugar de dividir el texto despu√©s de *n* caracteres, a menudo es mejor dividir por encabezado o recursivamente, con algunos metadatos adicionales.
* **Modelos de incrustaci√≥n**: Los modelos de incrustaci√≥n convierten el texto en representaciones vectoriales. Permite una comprensi√≥n m√°s profunda y matizada del lenguaje, esencial para realizar b√∫squedas sem√°nticas.
* **Bases de datos vectoriales**: Las bases de datos vectoriales (como [Chroma](https://www.trychroma.com/), [Pinecone](https://www.pinecone.io/), [Milvus

üìö **Referencias**:
* [LangChain - Divisores de texto](https://python.langchain.com/docs/modules/data_connection/document_transformers/): Lista de diferentes divisores de texto implementados en LangChain.
* [Biblioteca de Transformadores de Oraciones](https://www.sbert.net/): Biblioteca popular para modelos de incrustaci√≥n.
* [Tablero de L√≠deres MTEB](https://huggingface.co/spaces/mteb/leaderboard): Tablero de l√≠deres para modelos de incrustaci√≥n.
* [Las 5 Mejores Bases de Datos Vectoriales](https://www.datacamp.com/blog/the-top-5-vector-databases) por Moez Ali: Una comparaci√≥n de las mejores y m√°s populares bases de datos vectoriales.

---
### 3. Generaci√≥n Aumentada por Recuperaci√≥n (RAG)

Con RAG, los LLMs recuperan documentos contextuales de una base de datos para mejorar la precisi√≥n de sus respuestas. RAG es una forma popular de aumentar el conocimiento del modelo sin necesidad de afinamiento adicional.

* **Orquestadores**: Los orquestadores (como [LangChain](https://python.langchain.com/docs/get_started/introduction), [LlamaIndex](https://docs.llamaindex.ai/en/stable/), [FastRAG](https://github.com/IntelLabs/fastRAG), etc.) son marcos populares para conectar tus LLMs con herramientas, bases de datos, memorias, etc., y aumentar sus habilidades.
* **Recuperadores**: Las instrucciones de los usuarios no est√°n optimizadas para la recuperaci√≥n. Diferentes t√©cnicas (por ejemplo, recuperador de m√∫ltiples consultas, [HyDE](https://arxiv.org/abs/2212.10496), etc.) pueden aplicarse para reformular/ampliarlas y mejorar el rendimiento.
* **Memoria**: Para recordar instrucciones y respuestas anteriores, LLMs y chatbots como ChatGPT agregan este historial a su ventana de contexto. Este b√∫fer puede mejorarse con res√∫menes (por ejemplo, usando un LLM m√°s peque√±o), una tienda vectorial + RAG, etc.
* **Evaluaci√≥n**: Necesitamos evaluar tanto la recuperaci√≥n de documentos (precisi√≥n y recall del contexto) como las etapas de generaci√≥n (fidelidad y relevancia de la respuesta). Se puede simplificar con herramientas como [Ragas](https://github.com/explodinggradients/ragas/tree/main) y [DeepEval](https://github.com/confident-ai/deepeval).

üìö **Referencias**:
* [Llamaindex - Conceptos de alto nivel](https://docs.llamaindex.ai/en/stable/getting_started/concepts.html): Conceptos principales a conocer al construir tuber√≠as RAG.
* [Pinecone - Augmentaci√≥n de Recuperaci√≥n](https://www.pinecone.io/learn/series/langchain/langchain-retrieval-augmentation/): Visi√≥n general del proceso de augmentaci√≥n de recuperaci√≥n.
* [LangChain - Q&A con RAG](https://python.langchain.com/docs/use_cases/question_answering/quickstart): Tutorial paso a paso para construir una t√≠pica tuber√≠a RAG.
* [LangChain - Tipos de memoria](https://python.langchain.com/docs/modules/memory/types/): Lista de diferentes tipos de memorias con usos relevantes.
* [Pipeline RAG - M√©tricas](https://docs.ragas.io/en/stable/concepts/metrics/index.html): Visi√≥n general de las principales m√©tricas utilizadas para evaluar tuber√≠as RAG.

---
### 4. RAG Avanzado

Las aplicaciones de la vida real pueden requerir tuber√≠as complejas, incluyendo bases de datos SQL o de grafos, as√≠ como la selecci√≥n autom√°tica de herramientas y APIs relevantes. Estas t√©cnicas avanzadas pueden mejorar una soluci√≥n base y proporcionar caracter√≠sticas adicionales.

* **Construcci√≥n de consultas**: Los datos estructurados almacenados en bases de datos tradicionales requieren un lenguaje de consulta espec√≠fico como SQL, Cypher, metadatos, etc. Podemos traducir directamente la instrucci√≥n del usuario en una consulta para acceder a los datos con la construcci√≥n de consultas.
* **Agentes y herramientas**: Los agentes aumentan los LLMs seleccionando autom√°ticamente las herramientas m√°s relevantes para proporcionar una respuesta. Estas herramientas pueden ser tan simples como usar Google o Wikipedia, o m√°s complejas como un int√©rprete de Python o Jira.
* **Post-procesamiento**: Paso final que procesa las entradas que se alimentan al LLM. Mejora la relevancia y diversidad de los documentos recuperados con reordenamiento, [RAG-fusi√≥n](https://github.com/Raudaschl/rag-fusion), y clasificaci√≥n.

üìö **Referencias**:
* [LangChain - Construcci√≥n de Consultas](https://blog.langchain.dev/query-construction/): Publicaci√≥n de blog sobre diferentes tipos de construcci√≥n de consultas.
* [LangChain - SQL](https://python.langchain.com/docs/use_cases/qa_structured/sql): Tutorial sobre c√≥mo interactuar con bases de datos SQL con LLMs, involucrando Texto-a-SQL y un agente SQL opcional.
* [Pinecone - Agentes LLM](https://www.pinecone.io/learn/series/langchain/langchain-agents/): Introducci√≥n a agentes y herramientas con diferentes tipos.
* [Agentes Aut√≥nomos Potenciados por LLM](https://lilianweng.github.io/posts/2023-06-23-agent/) por Lilian Weng: Art√≠culo m√°s te√≥rico sobre agentes LLM.
* [LangChain - RAG de OpenAI](https://blog.langchain.dev/applying-openai-rag/): Visi√≥n general de las estrategias RAG empleadas por OpenAI, incluyendo post-procesamiento.

---
### 5. Optimizaci√≥n de la Inferencia

La generaci√≥n de texto es un proceso costoso que requiere hardware caro. Adem√°s de la cuantizaci√≥n, se han propuesto varias t√©cnicas para maximizar el rendimiento y reducir los costos de inferencia.

* **Atenci√≥n Flash**: Optimizaci√≥n del mecanismo de atenci√≥n para transformar su complejidad de cuadr√°tica a lineal, acelerando tanto el entrenamiento como la inferencia.
* **Cach√© de clave-valor**: Entiende el cach√© de clave-valor y las mejoras introducidas en la [Atenci√≥n de M√∫ltiples Consultas](https://arxiv.org/abs/1911.02150) (MQA) y la [Atenci√≥n de Consultas Agrupadas](https://arxiv.org/abs/2305.13245) (GQA).
* **Decodificaci√≥n especulativa**: Usa un modelo peque√±o para producir borradores que luego son revisados por un modelo m√°s grande para acelerar la generaci√≥n de texto.

üìö **Referencias**:
* [Inferencia en GPU](https://huggingface.co/docs/transformers/main/en/perf_infer_gpu_one) por Hugging Face: Explica c√≥mo optimizar la inferencia en GPUs.
* [Inferencia de LLM](https://www.databricks.com/blog/llm-inference-performance-engineering-best-practices) por Databricks: Mejores pr√°cticas sobre c√≥mo optimizar la inferencia de LLM en producci√≥n.
* [Optimizando LLMs para Velocidad y Memoria](https://huggingface.co/docs/transformers/main/en/llm_tutorial_optimization) por Hugging Face: Explica tres t√©cnicas principales para optimizar velocidad y memoria, a saber, cuantizaci√≥n, Atenci√≥n Flash e innovaciones arquitect√≥nicas.
* [Generaci√≥n Asistida](https://huggingface.co/blog/assisted-generation) por Hugging Face: Versi√≥n de Hugging Face de la decodificaci√≥n especulativa, es un post interesante sobre c√≥mo funciona con c√≥digo para implementarlo.

---
### 6. Desplegando LLMs

Desplegar LLMs a escala es una haza√±a de ingenier√≠a que puede requerir m√∫ltiples cl√∫steres de GPUs. En otros escenarios, demos y aplicaciones locales pueden lograrse con mucha menor complejidad.

* **Despliegue local**: La privacidad es una ventaja importante que los LLMs de c√≥digo abierto tienen sobre los privados. Servidores LLM locales ([LM Studio](https://lmstudio.ai/), [Ollama](https://ollama.ai/), [oobabooga](https://github.com/oobabooga/text-generation-webui), [kobold.cpp](https://github.com/LostRuins/koboldcpp), etc.) capitalizan esta ventaja para potenciar aplicaciones locales.
* **Despliegue de demostraciones**: Marcos como [Gradio](https://www.gradio.app/) y [Streamlit](https://docs.streamlit.io/) son √∫tiles para prototipar aplicaciones y compartir demos. Tambi√©n puedes alojarlos f√°cilmente en l√≠nea, por ejemplo, usando [Hugging Face Spaces](https://huggingface.co/spaces).
* **Despliegue de servidores**: Desplegar LLMs a escala requiere infraestructura en la nube (ver tambi√©n [SkyPilot](https://skypilot.readthedocs.io/en/latest/)) o local y a menudo aprovecha marcos de generaci√≥n de texto optimizados como [TGI](https://github.com/huggingface/text-generation-inference), [vLLM](https://github.com/vllm-project/vllm/tree/main), etc.
* **Despliegue en el borde**: En entornos restringidos, marcos de alto rendimiento como [MLC LLM](https://github.com/mlc-ai/mlc-llm) y [mnn-llm](https://github.com/wangzhaode/mnn-llm/blob/master/README_en.md) pueden desplegar LLMs en navegadores web, Android e iOS.

üìö **Referencias**:
* [Streamlit - Construye una aplicaci√≥n LLM b√°sica](https://docs.streamlit.io/knowledge-base/tutorials/build-conversational-apps): Tutorial para hacer una app b√°sica tipo ChatGPT usando Streamlit.
* [Contenedor de Inferencia LLM de HF](https://huggingface.co/blog/sagemaker-huggingface-llm): Despliega LLMs en Amazon SageMaker usando el contenedor de inferencia de Hugging Face.
* [Blog de Philschmid](https://www.philschmid.de/) por Philipp Schmid: Colecci√≥n de art√≠culos de alta calidad sobre despliegue de LLMs usando Amazon SageMaker.
* [Optimizando la latencia](https://hamel.dev/notes/llm/inference/03_inference.html) por Hamel Husain: Comparaci√≥n de TGI, vLLM, CTranslate2 y mlc en t√©rminos de rendimiento y latencia.

---
### 7. Asegurando LLMs

Adem√°s de los problemas de seguridad tradicionales asociados con el software, los LLMs tienen debilidades √∫nicas debido a la forma en que son entrenados y solicitados.

* **Hackeo de prompts**: Diferentes t√©cnicas relacionadas con la ingenier√≠a de prompts, incluyendo inyecci√≥n de prompts (instrucci√≥n adicional para secuestrar la respuesta del modelo), filtraci√≥n de datos/prompts (recuperar sus datos/prompts originales), y jailbreaking (crear prompts para eludir caracter√≠sticas de seguridad).
* **Puertas traseras**: Los vectores de ataque pueden apuntar al propio conjunto de datos de entrenamiento, envenenando los datos de entrenamiento (por ejemplo, con informaci√≥n falsa) o creando puertas traseras (disparadores secretos para cambiar el comportamiento del modelo durante la inferencia).
* **Medidas defensivas**: La mejor manera de proteger tus aplicaciones LLM es probarlas contra estas vulnerabilidades (por ejemplo, usando equipos rojos y controles como [garak](https://github.com/leondz/garak/)) y observarlas en producci√≥n (con un marco como [langfuse](https://github.com/langfuse/langfuse)).

üìö **Referencias**:
* [OWASP Top 10 para aplicaciones de LLM](https://owasp.org/www-project-top-10-for-large-language-model-applications/) por HEGO Wiki: Lista de las 10 vulnerabilidades cr√≠ticas m√°s vistas en aplicaciones LLM.
* [Primer sobre Inyecci√≥n de Prompts](https://github.com/jthack/PIPE) por Joseph Thacker: Gu√≠a corta dedicada a la inyecci√≥n de prompts para ingenieros.
* [Seguridad LLM](https://llmsecurity.net/) por [@llm_sec](https://twitter.com/llm_sec): Lista extensiva de recursos relacionados con la seguridad LLM.
* [Equipos rojos en LLMs](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/red-teaming) por Microsoft: Gu√≠a sobre c√≥mo realizar equipos rojos con LLMs.

---
## Acknowledgements

This roadmap was inspired by the excellent [DevOps Roadmap](https://github.com/milanm/DevOps-Roadmap) from Milan Milanoviƒá and Romano Roth.

Special thanks to:

* Thomas Thelen for motivating me to create a roadmap
* Andr√© Frade for his input and review of the first draft
* Dino Dunn for providing resources about LLM security

*Disclaimer: I am not affiliated with any sources listed here.*

---
<p align="center">
  <a href="https://star-history.com/#machinelearnear/curso-llm-generative-ai&Date">
    <img src="https://api.star-history.com/svg?repos=machinelearnear/curso-llm-generative-ai&type=Date" alt="Star History Chart">
  </a>
</p>
