<div align="center">
  <h1>ğŸ¤– Curso de IA Generativa y Modelos de Lenguaje Grandes (LLMs)</h1>
  <p align="center">
    ğŸ¦ <a href="https://twitter.com/nicolasmetallo">twitter</a> â€¢ 
    ğŸ’» <a href="https://www.machinelearnear.com/">web</a> â€¢ 
    ğŸ“¹ <a href="https://www.youtube.com/@machinelearnear">youtube</a> â€¢ 
    ğŸ’» <a href="https://github.com/mlabonne/llm-course">repo original de @mlabonne</a>
  </p>
</div>
<br/>

Este curso de IA generativa y LLMs va a estar dividido en 3 partes:

1. ğŸ§© **Fundamentos de IA** cubre conocimientos esenciales sobre matemÃ¡ticas, Python y redes neuronales.
2. ğŸ§‘â€ğŸ”¬ **CientÃ­fico/a de LLMs** se enfoca en construir los mejores LLMs posibles usando las tÃ©cnicas mÃ¡s recientes.
3. ğŸ‘· **Ingeniero/a de LLMs** se concentra en crear aplicaciones basadas en LLM y desplegarlas.

>[!NOTE]  
>todo este laburo se basa en el [repo de @mlabonne](https://github.com/mlabonne/llm-course), **vayan a meterle una â­ ya mismo!**

## ğŸ“¹ Clases en video

... proximamente ...

## ğŸ“¹ Videos random

Una lista de algunos videos que hice ([@machinelearnear](https://www.youtube.com/@machinelearnear)) que tocan varios de estos temas

- ğŸ“ **Contenido**
  - ğŸ“¹ [CÃ³mo es que funciona realmente Stable Diffusion? (Guia ilustrada paso a paso)](https://www.youtube.com/watch?v=00NV4EXcpLQ&ab_channel=machinelearnear)
  - ğŸ“¹ [Como crear ChatGPT desde 0 explicado](https://www.youtube.com/watch?v=4uXeflZ8q8w&ab_channel=machinelearnear)
  - ğŸ“¹ [Habilidades emergentes de GPT-3.5](https://www.youtube.com/watch?v=TYFy0wZpJuY&ab_channel=machinelearnear)
  - ğŸ“¹ [Reinforcement Learning from Human Feedback](https://www.youtube.com/watch?v=tzPuVAJ3XoI&ab_channel=machinelearnear)
  - ğŸ“¹ [In-Context Learning & Gradient Descent](https://www.youtube.com/watch?v=TMYpH8wsGFU&ab_channel=machinelearnear)
  - ğŸ“¹ [Que hace que un agente de diÃ¡logo sea Ãºtil?](https://www.youtube.com/watch?v=DRf4j0EpYuQ&ab_channel=machinelearnear)
  - ğŸ“¹ ["Estado de GPT" por Andrej Karpathy](https://www.youtube.com/watch?v=aqv6Sd67R7M&ab_channel=machinelearnear)
  - ğŸ“¹ [Como las empresas crean aplicaciones con LLMs](https://www.youtube.com/watch?v=7YDxI66fySk&ab_channel=machinelearnear)
  - ğŸ“¹ [Tutorial para hacer una aplicaciÃ³n con GPT4, LangChain, Whisper, y otros](https://www.youtube.com/watch?v=1Rpn4lrshlo&ab_channel=machinelearnear)
  - ğŸ“¹ [Ingenieria de Prompts (Octubre 2023)](https://www.youtube.com/watch?v=21pUaHVlHaQ&ab_channel=machinelearnear)

## ğŸ“ Notebooks

Una lista de notebooks y artÃ­culos relacionados con modelos de lenguaje grandes hechos por [@mlabonne](https://github.com/mlabonne).

- ğŸ“ **Herramientas**
  - ğŸ§ **LLM AutoEval** - EvalÃºa automÃ¡ticamente tus LLMs usando RunPod. [Abrir en Colab](https://colab.research.google.com/)
  - ğŸ¥± **LazyMergekit** - Fusiona modelos fÃ¡cilmente usando mergekit en un clic. [Abrir en Colab](https://colab.research.google.com/)
  - âš¡ **AutoGGUF** - Cuantiza LLMs en formato GGUF en un click. [Abrir en Colab](https://colab.research.google.com/)
  - ğŸŒ³ **Ãrbol genealÃ³gico de modelos** - Visualiza el Ã¡rbol genealÃ³gico de modelos fusionados. [Abrir en Colab](https://colab.research.google.com/)

- ğŸ› **Ajuste fino**
  - ğŸ§ **Ajuste fino de Llama-2 en Google Colab** - GuÃ­a paso a paso para afinar tu primer modelo Llama 2. [ArtÃ­culo](https://mlabonne.github.io/blog/posts/Fine_Tune_Your_Own_Llama_2_Model_in_a_Colab_Notebook.html) | [Abrir en Colab](https://colab.research.google.com/)
  - ğŸ¥± **Ajuste fino de LLMs con Axolotl** - GuÃ­a de principio a fin para la herramienta de vanguardia para afinamiento. [ArtÃ­culo](https://mlabonne.github.io/blog/posts/A_Beginners_Guide_to_LLM_Finetuning.html) | [Abrir en Colab](https://colab.research.google.com/)
  - âš¡ **Ajuste fino de Mistral-7b con DPO** - Mejora el rendimiento de modelos afinados supervisados con DPO. [ArtÃ­culo](https://medium.com/towards-data-science/fine-tune-a-mistral-7b-model-with-direct-preference-optimization-708042745aac) | [Abrir en Colab](https://colab.research.google.com/)

- ğŸ’¾ **CuantizaciÃ³n**
  - 1ï¸âƒ£ **IntroducciÃ³n a la cuantizaciÃ³n** - OptimizaciÃ³n de LLMs usando cuantizaciÃ³n de 8 bits. [ArtÃ­culo](https://mlabonne.github.io/blog/posts/Introduction_to_Weight_Quantization.html) | [Abrir en Colab](https://colab.research.google.com/)
  - 2ï¸âƒ£ **CuantizaciÃ³n de 4 bits usando GPTQ** - Cuantiza tus propios LLMs de cÃ³digo abierto. [ArtÃ­culo](https://mlabonne.github.io/blog/4bit_quantization/) | [Abrir en Colab](https://colab.research.google.com/)
  - 3ï¸âƒ£ **CuantizaciÃ³n con GGUF y `llama.cpp`** - Llama 2 con llama.cpp y sube versiones GGUF al HF Hub. [ArtÃ­culo](https://mlabonne.github.io/blog/posts/Quantize_Llama_2_models_using_ggml.html) | [Abrir en Colab](https://colab.research.google.com/)
  - 4ï¸âƒ£ **ExLlamaV2** - Cuantiza y corre modelos EXL2 y sÃºbelos al HF Hub. [ArtÃ­culo](https://mlabonne.github.io/blog/posts/ExLlamaV2_The_Fastest_Library_to_Run%C2%A0LLMs.html) | [Abrir en Colab](https://colab.research.google.com/)

- ğŸ“š **Otros**
  - ğŸ“– **Estrategias de decodificaciÃ³n en LLMs** - Una guÃ­a para la generaciÃ³n de texto desde la bÃºsqueda por haz hasta el muestreo de nÃºcleo. [ArtÃ­culo](https://mlabonne.github.io/blog/posts/2022-06-07-Decoding_strategies.html) | [Abrir en Colab](https://colab.research.google.com/)
  - ğŸŒ **Visualizar el paisaje de pÃ©rdida de GPT-2** - GrÃ¡fico 3D del paisaje de pÃ©rdida basado en perturbaciones de peso. [Tweet](https://twitter.com/maximelabonne/status/1667618081844219904) | [Abrir en Colab](https://colab.research.google.com/)
  - ğŸš€ **Mejorar ChatGPT con grafos de conocimiento** - AmplÃ­a las respuestas de ChatGPT con grafos de conocimiento. [ArtÃ­culo](https://mlabonne.github.io/blog/posts/Article_Improve_ChatGPT_with_Knowledge_Graphs.html) | [Abrir en Colab](https://colab.research.google.com/)
  - ğŸ›  **Fusionar LLMs usando `mergekit`** - Crea tus propios modelos fÃ¡cilmente, Â¡no se necesita GPU! [ArtÃ­culo](https://towardsdatascience.com/merge-large-language-models-with-mergekit-2118fb392b54) | [Abrir en Colab](https://colab.research.google.com/)

## ğŸ§© Roadmap para aprender fundamentos de IA

```
ğŸ“
â”œâ”€â”€ ğŸ“š MatemÃ¡ticas para el aprendizaje automÃ¡tico
â”‚   â”œâ”€â”€ ğŸ§® Ãlgebra lineal
â”‚   â”œâ”€â”€ ğŸ”¢ CÃ¡lculo
â”‚   â””â”€â”€ ğŸ“Š Probabilidad y estadÃ­stica
â”œâ”€â”€ ğŸ Python para el aprendizaje automÃ¡tico
â”‚   â”œâ”€â”€ ğŸ’» Fundamentos de Python
â”‚   â””â”€â”€ ğŸ“Š Bibliotecas de ciencia de datos
â”œâ”€â”€ ğŸ§  Redes neuronales
â”‚   â”œâ”€â”€ ğŸ“– Fundamentos
â”‚   â”œâ”€â”€ âš™ï¸ Entrenamiento y optimizaciÃ³n
â”‚   â””â”€â”€ âš ï¸ Sobreajuste
â””â”€â”€ ğŸ’¬ Procesamiento de lenguaje natural
    â”œâ”€â”€ ğŸ“ Preprocesamiento de texto
    â”œâ”€â”€ âœ¨ TÃ©cnicas de extracciÃ³n de caracterÃ­sticas
    â”œâ”€â”€ ğŸª„ Representaciones de palabras
    â””â”€â”€ ğŸ”„ Redes neuronales recurrentes (RNN)
```
### MatemÃ¡ticas para aprendizaje automÃ¡tico

Antes de dominar el aprendizaje automÃ¡tico (ML o machine learning), es importante entender los conceptos matemÃ¡ticos fundamentales que impulsan estos algoritmos.

- **Ãlgebra lineal**: Esto es crucial para entender muchos algoritmos, especialmente aquellos usados en aprendizaje profundo (deep learning). Conceptos clave incluyen vectores, matrices, determinantes, valores y vectores propios, espacios vectoriales y transformaciones lineales.
- **CÃ¡lculo**: Muchos algoritmos de aprendizaje automÃ¡tico involucran la optimizaciÃ³n de funciones continuas, lo que requiere un entendimiento de derivadas, integrales, lÃ­mites y series. El cÃ¡lculo multivariable y el concepto de gradientes tambiÃ©n son importantes.
- **Probabilidad y estadÃ­stica**: Estos son cruciales para entender cÃ³mo los modelos aprenden de datos y hacen predicciones. Conceptos clave incluyen teorÃ­a de probabilidad, variables aleatorias, distribuciones de probabilidad, expectativas, varianza, covarianza, correlaciÃ³n, pruebas de hipÃ³tesis, intervalos de confianza, estimaciÃ³n de mÃ¡xima verosimilitud e inferencia Bayesiana.

ğŸ“š **Referencias**:

- [3Blue1Brown, La Esencia del Ã¡lgebra lineal](https://www.youtube.com/watch?v=fNk_zzaMoSs&list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab): Serie de videos que proporcionan una intuiciÃ³n geomÃ©trica de estos conceptos.
- [StatQuest con Josh Starmer, Fundamentos de estadÃ­stica](https://www.youtube.com/watch?v=qBigTkBLU6g&list=PLblh5JKOoLUK0FLuzwntyYI10UQFUhsY9): Ofrece explicaciones simples y claras para muchos conceptos estadÃ­sticos.
- [IntuiciÃ³n AP de estadÃ­sticas por Ms Aerin](https://automata88.medium.com/list/cacc224d5e7d): Lista de artÃ­culos en Medium que proporcionan la intuiciÃ³n detrÃ¡s de cada distribuciÃ³n de probabilidad.
- [Ãlgebra lineal inmersiva](https://immersivemath.com/ila/learnmore.html): Otra interpretaciÃ³n visual del Ã¡lgebra lineal.
- [Khan Academy, Ãlgebra lineal](https://www.khanacademy.org/math/linear-algebra): Genial para principiantes ya que explica los conceptos de manera muy intuitiva.
- [Khan Academy, CÃ¡lculo](https://www.khanacademy.org/math/calculus-1): Un curso interactivo que cubre todos los fundamentos del cÃ¡lculo.
- [Khan Academy, Probabilidad y estadÃ­stica](https://www.khanacademy.org/math/statistics-probability): Presenta el material de forma fÃ¡cil de entender.

---

### Python para aprendizaje automÃ¡tico

Python es un lenguaje de programaciÃ³n poderoso y flexible que es particularmente bueno para el aprendizaje automÃ¡tico, gracias a su legibilidad, consistencia y el robusto ecosistema de librerÃ­as de ciencia de datos.

- **Fundamentos de Python**: Programar en Python requiere un buen entendimiento de la sintaxis bÃ¡sica, tipos de datos, manejo de errores y programaciÃ³n orientada a objetos.
- **LibrerÃ­as de ciencia de datos**: Incluye familiaridad con `NumPy` para operaciones numÃ©ricas, `Pandas` para manipulaciÃ³n y anÃ¡lisis de datos, `Matplotlib` y `Seaborn` para visualizaciÃ³n de datos.
- **Pre-procesamiento de datos**: Esto involucra escalado y normalizaciÃ³n de caracterÃ­sticas (features), manejo de datos faltantes, detecciÃ³n de valores atÃ­picos (outliers), codificaciÃ³n de datos categÃ³ricos y divisiÃ³n de datos en conjuntos de entrenamiento, validaciÃ³n y prueba.
- **LibrerÃ­as de aprendizaje automÃ¡tico**: Saber usar `Scikit-learn`, una biblioteca que proporciona una amplia selecciÃ³n de algoritmos de aprendizaje supervisado y no supervisado, es vital. Entender cÃ³mo implementar algoritmos como regresiÃ³n lineal, regresiÃ³n logÃ­stica, Ã¡rboles de decisiÃ³n, bosques aleatorios, vecinos mÃ¡s cercanos (K-NN) y agrupamiento por K-medias es importante. TÃ©cnicas de reducciÃ³n de dimensionalidad como PCA y t-SNE tambiÃ©n son Ãºtiles para visualizar datos de alta dimensiÃ³n.

ğŸ“š **Referencias**:

- [Real Python](https://realpython.com/): Un recurso comprensivo con artÃ­culos y tutoriales tanto para conceptos de Python principiantes como avanzados.
- [freeCodeCamp, Aprende Python](https://www.youtube.com/watch?v=rfscVS0vtbw): Video largo que proporciona una introducciÃ³n completa a todos los conceptos fundamentales en Python.
- [Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/): Libro digital gratuito que es un gran recurso para aprender pandas, NumPy, Matplotlib y Seaborn.
- [freeCodeCamp, Aprendizaje automÃ¡tico para todos](https://youtu.be/i_LwzRVP7bg): IntroducciÃ³n prÃ¡ctica a diferentes algoritmos de aprendizaje automÃ¡tico para principiantes.
- [Udacity, IntroducciÃ³n al aprendizaje automÃ¡tico](https://www.udacity.com/course/intro-to-machine-learning--ud120): Curso gratuito que cubre PCA y varios otros conceptos de aprendizaje automÃ¡tico.

---

### Redes neuronales

Las redes neuronales son una parte fundamental de muchos modelos de aprendizaje automÃ¡tico, particularmente en el Ã¡mbito del aprendizaje profundo. Para utilizarlas efectivamente, es esencial tener un entendimiento comprensivo de su diseÃ±o y mecÃ¡nicas.

- **Fundamentos**: Esto incluye entender la estructura de una red neuronal como capas, pesos, sesgos y funciones de activaciÃ³n (sigmoide, tanh, ReLU, etc.)
- **Entrenamiento y optimizaciÃ³n**: FamiliarÃ­zate con la retropropagaciÃ³n y diferentes tipos de funciones de pÃ©rdida, como Error CuadrÃ¡tico Medio (MSE) y EntropÃ­a Cruzada. Entiende varios algoritmos de optimizaciÃ³n como Descenso de Gradiente, Descenso de Gradiente EstocÃ¡stico, RMSprop y Adam.
- **Sobreajuste (over-fitting)**: Entender el concepto de sobreajuste (donde un modelo rinde bien en datos de entrenamiento pero pobremente en datos no vistos) y aprender varias tÃ©cnicas de regularizaciÃ³n (abandono, regularizaciÃ³n L1/L2, detenciÃ³n temprana, aumento de datos) para prevenirlo.
- **Implementar un perceptrÃ³n multicapa (MLP)**: Construye un `MLP`, tambiÃ©n conocido como una red completamente conectada (fully-connected network), usando `PyTorch`.

ğŸ“š **Referencias**:

- [3Blue1Brown, "Pero, Â¿quÃ© es una red neuronal?"](https://www.youtube.com/watch?v=aircAruvnKk): Este video ofrece una explicaciÃ³n intuitiva de las redes neuronales y su funcionamiento interno.
- [freeCodeCamp, Curso acelerado de aprendizaje profundo](https://www.youtube.com/watch?v=VyWAvY2CF9c): Este video introduce de manera eficiente todos los conceptos mÃ¡s importantes en aprendizaje profundo.
- [Fast.ai, Aprendizaje profundo prÃ¡ctico](https://course.fast.ai/): Curso gratuito diseÃ±ado para personas con experiencia en programaciÃ³n que quieran aprender sobre aprendizaje profundo.
- [Patrick Loeber, Tutoriales de PyTorch](https://www.youtube.com/playlist?list=PLqnslRFeH2UrcDBWF5mfPGpqQDSta6VK4): Serie de videos para principiantes completos para aprender sobre PyTorch.

---

### Procesamiento de lenguaje natural (NLP)

NLP es una rama fascinante de la inteligencia artificial que cierra la brecha entre el lenguaje humano y la comprensiÃ³n de las mÃ¡quinas. Desde el procesamiento de texto simple hasta la comprensiÃ³n de matices lingÃ¼Ã­sticos, NLP juega un papel crucial en muchas aplicaciones como traducciÃ³n, anÃ¡lisis de sentimientos, chatbots y mucho mÃ¡s.

- **Preprocesamiento de texto**: Aprende varios pasos de preprocesamiento de texto como tokenizaciÃ³n (dividir texto en palabras o frases), stemming (reducir palabras a su forma raÃ­z), lematizaciÃ³n (similar al stemming pero considera el contexto), eliminaciÃ³n de palabras vacÃ­as, etc.
- **TÃ©cnicas de extracciÃ³n de caracterÃ­sticas**: FamiliarÃ­zate con tÃ©cnicas para convertir datos de texto en un formato que pueda ser entendido por algoritmos de aprendizaje automÃ¡tico. Los mÃ©todos clave incluyen "bolsa de palabras" (BoW), "frecuencia de tÃ©rmino", inversa de frecuencia de documentos (`TF-IDF`) y n-gramas.
- **Embeddings de palabras**: Los embeddings de palabras son un tipo de representaciÃ³n de palabras que permite que palabras con significados similares tengan representaciones similares. Los mÃ©todos clave incluyen `Word2Vec`, `GloVe` y `FastText`.
- **Redes neuronales recurrentes (RNNs)**: Entiende el funcionamiento de RNNs, un tipo de red neuronal diseÃ±ada para trabajar con datos secuenciales. Explora LSTMs y GRUs, dos variantes de RNN que son capaces de aprender dependencias a largo plazo.

ğŸ“š **Referencias**:

- [RealPython, NLP con `spaCy` en Python](https://realpython.com/natural-language-processing-spacy-python/): GuÃ­a exhaustiva sobre la biblioteca spaCy para tareas de NLP en Python.
- [Kaggle, GuÃ­a de NLP](https://www.kaggle.com/learn-guide/natural-language-processing): Unos cuadernos y recursos para una explicaciÃ³n prÃ¡ctica de NLP en Python.
- [Jay Alammar, Word2Vec ilustrado](https://jalammar.github.io/illustrated-word2vec/): Una buena referencia para entender la famosa arquitectura Word2Vec.
- [Jake Tae, PyTorch RNN desde cero](https://jaketae.github.io/study/pytorch-rnn/): ImplementaciÃ³n prÃ¡ctica y simple de modelos RNN, LSTM y GRU en PyTorch.
- [Blog de Colah, Entendiendo las redes LSTM](https://colah.github.io/posts/2015-08-Understanding-LSTMs/): Un artÃ­culo mÃ¡s teÃ³rico sobre la red LSTM.

## ğŸ§‘â€ğŸ”¬ Roadmap para ser cientÃ­fico/a de LLMs

Esta secciÃ³n del curso se enfoca en aprender cÃ³mo construir los mejores LLMs posibles usando las tÃ©cnicas mÃ¡s recientes.

```
ğŸ“ 
â”œâ”€â”€ ğŸ— Arquitectura de LLMs
â”‚   â”œâ”€â”€ ğŸŒ VisiÃ³n general
â”‚   â”œâ”€â”€ ğŸ”¤ TokenizaciÃ³n
â”‚   â”œâ”€â”€ ğŸ§  Mecanismos de atenciÃ³n
â”‚   â””â”€â”€ âœï¸ GeneraciÃ³n de texto
â”œâ”€â”€ ğŸ›  ConstrucciÃ³n de un dataset de instrucciones
â”‚   â”œâ”€â”€ ğŸ¦™ Dataset tipo Alpaca
â”‚   â”œâ”€â”€ ğŸ§ª TÃ©cnicas avanzadas
â”‚   â”œâ”€â”€ ğŸš¿ Filtrado de datos
â”‚   â””â”€â”€ ğŸ“ Plantillas de prompts
â”œâ”€â”€ ğŸ”„ Pre-entrenamiento de modelos
â”‚   â”œâ”€â”€ ğŸ“Š Pipeline de datos
â”‚   â”œâ”€â”€ ğŸ“– Modelado de lenguaje causal
â”‚   â”œâ”€â”€ ğŸ“ˆ Leyes de escalado
â”‚   â””â”€â”€ ğŸ’» ComputaciÃ³n de alto rendimiento
â”œâ”€â”€ ğŸ› Ajuste fino supervisado
â”‚   â”œâ”€â”€ ğŸ“š Ajuste fino completo
â”‚   â”œâ”€â”€ ğŸ§® LoRA y QLoRA
â”‚   â”œâ”€â”€ ğŸ¸ Axolotl
â”‚   â””â”€â”€ ğŸš€ DeepSpeed
â”œâ”€â”€ ğŸ¤– RLHF
â”‚   â”œâ”€â”€ ğŸ“ MÃ©tricas tradicionales
â”‚   â”œâ”€â”€ ğŸŒ Benchmarks generales
â”‚   â”œâ”€â”€ ğŸ¯ Benchmarks especÃ­ficos de tareas
â”‚   â””â”€â”€ ğŸ‘¥ EvaluaciÃ³n humana
â”œâ”€â”€ ğŸ”¢ CuantizaciÃ³n
â”‚   â”œâ”€â”€ ğŸ›  TÃ©cnicas base
â”‚   â”œâ”€â”€ ğŸ¦™ GGUF y llama.cpp
â”‚   â”œâ”€â”€ âš¡ GPTQ y EXL2
â”‚   â””â”€â”€ ğŸ‹ï¸â€â™‚ï¸ AWQ
â””â”€â”€ ğŸŒŸ Nuevas tendencias
    â”œâ”€â”€ ğŸ“ Embeddings posicionales
    â”œâ”€â”€ ğŸ”„ FusiÃ³n de modelos
    â”œâ”€â”€ ğŸ§‘â€ğŸ”¬ Mix de expertos
    â””â”€â”€ ğŸ­ Modelos multimodales
```

### Arquitectura de modelos de lenguaje grandes (LLMs)

Aunque no es necesario un conocimiento profundo sobre la arquitectura Transformer, es importante tener un buen entendimiento de sus entradas (tokens) y salidas (logits). El mecanismo de atenciÃ³n bÃ¡sico es otro componente crucial para dominar, ya que se introducen versiones mejoradas mÃ¡s adelante.

* **Vista de alto nivel**: Revisar la arquitectura Transformer de codificador-decodificador, y mÃ¡s especÃ­ficamente la arquitectura GPT solo de decodificador, que se usa en todos los LLMs modernos.
* **TokenizaciÃ³n**: Entender cÃ³mo convertir datos de texto crudo en un formato que el modelo pueda entender, lo que involucra dividir el texto en tokens (generalmente palabras o subpalabras).
* **Mecanismos de atenciÃ³n**: Comprender la teorÃ­a detrÃ¡s de los mecanismos de atenciÃ³n, incluyendo la autoatenciÃ³n y la atenciÃ³n de producto punto escalado, que permite al modelo enfocarse en diferentes partes de la entrada al producir una salida.
* **GeneraciÃ³n de texto**: Aprender sobre las diferentes maneras en que el modelo puede generar secuencias de salida. Las estrategias comunes incluyen la decodificaciÃ³n Ã¡vida, bÃºsqueda por haz, muestreo top-k y muestreo de nÃºcleo.

ğŸ“š **Referencias**:
- [Transformers ilustrado](https://jalammar.github.io/illustrated-transformer/) por Jay Alammar: Una explicaciÃ³n visual e intuitiva del modelo Transformer.
- [GPT-2 ilustrado](https://jalammar.github.io/illustrated-gpt2/) por Jay Alammar: MÃ¡s importante que el artÃ­culo anterior, se centra en la arquitectura GPT, muy similar a la de Llama.
- [VisualizaciÃ³n de LLMs](https://bbycroft.net/llm) por Brendan Bycroft: IncreÃ­ble visualizaciÃ³n 3D de lo que sucede dentro de un LLM.
* [`nanoGPT`](https://www.youtube.com/watch?v=kCc8FmEb1nY) por Andrej Karpathy: Video de 2 horas en YouTube para reimplementar GPT desde cero (para programadores).
* [Â¿AtenciÃ³n? Â¡AtenciÃ³n!](https://lilianweng.github.io/posts/2018-06-24-attention/) por Lilian Weng: Introduce la necesidad de atenciÃ³n de una manera mÃ¡s formal.
* [Estrategias de decodificaciÃ³n en LLMs](https://mlabonne.github.io/blog/posts/2023-06-07-Decoding_strategies.html): Proporciona cÃ³digo y una introducciÃ³n visual a las diferentes estrategias de decodificaciÃ³n para generar texto.

---
### Construyendo un dataset de instrucciones

Aunque es fÃ¡cil encontrar datos crudos de Wikipedia y otros sitios web, es difÃ­cil recolectar pares de instrucciones y respuestas en la naturaleza. Como en el aprendizaje automÃ¡tico tradicional, la calidad del conjunto de datos influirÃ¡ directamente en la calidad del modelo, lo que significa que podrÃ­a ser el componente mÃ¡s importante en el proceso de afinamiento.

* **Conjunto de datos tipo [Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html)**: Generar datos sintÃ©ticos desde cero con la API de OpenAI (GPT). Puedes especificar semillas y prompts del sistema para crear un conjunto de datos diverso.
* **TÃ©cnicas avanzadas**: Aprender cÃ³mo mejorar conjuntos de datos existentes con [Evol-Instruct](https://arxiv.org/abs/2304.12244), cÃ³mo generar datos sintÃ©ticos de alta calidad como en los papeles [Orca](https://arxiv.org/abs/2306.02707) y [phi-1](https://arxiv.org/abs/2306.11644).
* **Filtrado de datos**: TÃ©cnicas tradicionales que involucran regex, eliminaciÃ³n de duplicados cercanos, enfocÃ¡ndose en respuestas con un alto nÃºmero de tokens, etc.
* **Plantillas de prompts**: No existe una manera estÃ¡ndar verdadera de formatear instrucciones y respuestas, por lo que es importante saber sobre las diferentes plantillas de chat, como [ChatML](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/chatgpt?tabs=python&pivots=programming-language-chat-ml), [Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html), etc.

ğŸ“š **Referencias**:
* [Preparando un dataset para ajuste de instrucciones](https://wandb.ai/capecape/alpaca_ft/reports/How-to-Fine-Tune-an-LLM-Part-1-Preparing-a-Dataset-for-Instruction-Tuning--Vmlldzo1NTcxNzE2) por Thomas Capelle: ExploraciÃ³n de los conjuntos de datos Alpaca y Alpaca-GPT4 y cÃ³mo formatearlos.
* [Generando un dataset de instrucciÃ³n clÃ­nica](https://medium.com/mlearning-ai/generating-a-clinical-instruction-dataset-in-portuguese-with-langchain-and-gpt-4-6ee9abfa41ae) por Solano Todeschini: Tutorial sobre cÃ³mo crear un conjunto de datos de instrucciÃ³n sintÃ©tico usando GPT-4.
* [GPT 3.5 para clasificaciÃ³n de noticias](https://medium.com/@kshitiz.sahay26/how-i-created-an-instruction-dataset-using-gpt-3-5-to-fine-tune-llama-2-for-news-classification-ed02fe41c81f) por Kshitiz Sahay: Uso de GPT 3.5 para crear un conjunto de datos de instrucciÃ³n para afinar Llama 2 para clasificaciÃ³n de noticias.
* [CreaciÃ³n de conjunto de datos para ajuste fino de LLMs](https://colab.research.google.com/drive/1GH8PW9-zAe4cXEZyOIE-T9uHXblIldAg?usp=sharing): Cuaderno que contiene algunas tÃ©cnicas para filtrar un conjunto de datos y subir el resultado.
* [Plantilla de prompts](https://huggingface.co/blog/chat-templates) por Matthew Carrigan: PÃ¡gina de Hugging Face sobre plantillas de prompts.

---
### Pre-entrenamiento de modelos

El pre-entrenamiento es un proceso muy largo y costoso, por lo que no es el foco de este curso. Es bueno tener algÃºn nivel de entendimiento sobre lo que sucede durante el preentrenamiento, pero la experiencia prÃ¡ctica no es requerida.

* **Pipeline de datos**: El preentrenamiento requiere enormes conjuntos de datos (por ejemplo, [Llama 2](https://arxiv.org/abs/2307.09288) fue entrenado en 2 billones de tokens) que necesitan ser filtrados, tokenizados y agrupados con un vocabulario predefinido.
* **Modelado de lenguaje causal**: Aprender la diferencia entre modelado de lenguaje causal y modelado de lenguaje enmascarado, asÃ­ como la funciÃ³n de pÃ©rdida utilizada en este caso. Para un preentrenamiento eficiente, aprender mÃ¡s sobre [Megatron-LM](https://github.com/NVIDIA/Megatron-LM) o [gpt-neox](https://github.com/EleutherAI/gpt-neox).
* **Leyes de escalamiento ie. Chinchilla scaling laws**: Las [leyes de escalamiento](https://arxiv.org/pdf/2001.08361.pdf) describen el rendimiento esperado del modelo basado en el tamaÃ±o del modelo, tamaÃ±o del conjunto de datos y la cantidad de cÃ³mputo usado para el entrenamiento.
* **ComputaciÃ³n de alto rendimiento (HPC)**: Fuera del alcance aquÃ­, pero mÃ¡s conocimiento sobre HPC es fundamental si estÃ¡s planeando crear tu propio LLM desde cero (hardware, carga de trabajo distribuida, etc.).

ğŸ“š **Referencias**:
* [`LLMDataHub`](https://github.com/Zjh-819/LLMDataHub) por Junhao Zhao: Lista curada de conjuntos de datos para preentrenamiento, afinamiento y RLHF.
* [Entrenando un modelo de lenguaje causal desde cero](https://huggingface.co/learn/nlp-course/chapter7/6?fw=pt) por Hugging Face: Preentrena un modelo GPT-2 desde cero usando la biblioteca transformers.
* [`TinyLlama`](https://github.com/jzhang38/TinyLlama) por Zhang et al.: Consulta este proyecto para obtener un buen entendimiento de cÃ³mo se entrena un modelo Llama desde cero.
* [Modelado de lenguaje causal](https://huggingface.co/docs/transformers/tasks/language_modeling) por Hugging Face: Explica la diferencia entre modelado de lenguaje causal y enmascarado y cÃ³mo afinar rÃ¡pidamente un modelo DistilGPT-2.
* [Las zarpadas implicaciones de Chinchilla](https://www.lesswrong.com/posts/6Fpvch8RR29qLEWNH/chinchilla-s-wild-implications) por nostalgebraist: Discute las leyes de escalamiento y explica lo que significan para los LLMs en general.
* [BLOOM](https://bigscience.notion.site/BLOOM-BigScience-176B-Model-ad073ca07cdf479398d5f95d88e218c4) por BigScience: PÃ¡gina de Notion que describe cÃ³mo se construyÃ³ el modelo BLOOM, con mucha informaciÃ³n Ãºtil sobre la parte de ingenierÃ­a y los problemas que se encontraron.
* [BitÃ¡cora de entrenamiento de OPT-175](https://github.com/facebookresearch/metaseq/blob/main/projects/OPT/chronicles/OPT175B_Logbook.pdf) por Meta: Registros de investigaciÃ³n que muestran lo que saliÃ³ mal y lo que saliÃ³ bien. Ãštil si planeas preentrenar un modelo de lenguaje grande (en este caso, 175B parÃ¡metros).
* [LLM 360](https://www.llm360.ai/): Un marco para LLMs de cÃ³digo abierto con cÃ³digo de entrenamiento y preparaciÃ³n de datos, datos, mÃ©tricas y modelos.

---
### Ajuste fino supervisado

Los modelos pre-entrenados solo estÃ¡n entrenados en una tarea de predicciÃ³n del siguiente token, por lo que no son asistentes Ãºtiles. SFT te permite ajustarlos para responder a instrucciones. AdemÃ¡s, te permite afinar tu modelo en cualquier dato (privado, no visto por GPT-4, etc.) y usarlo sin tener que pagar por una API como la de OpenAI.

* **Ajuste fino completo**: El ajuste fino (fine-tuning) completo se refiere a entrenar todos los parÃ¡metros en el modelo. No es una tÃ©cnica eficiente, pero produce resultados ligeramente mejores.
* [**LoRA**](https://arxiv.org/abs/2106.09685): Una tÃ©cnica de afinamiento eficiente en parÃ¡metros (PEFT) basada en adaptadores de rango bajo. En lugar de entrenar todos los parÃ¡metros, solo entrenamos estos adaptadores.
* [**QLoRA**](https://arxiv.org/abs/2305.14314): Otra PEFT basada en LoRA, que tambiÃ©n cuantiza los pesos del modelo en 4 bits e introduce optimizadores paginados para manejar picos de memoria. CombÃ­nalo con [Unsloth](https://github.com/unslothai/unsloth) para correrlo eficientemente en un cuaderno Colab gratuito.
* **[Axolotl](https://github.com/OpenAccess-AI-Collective/axolotl)**: Una herramienta de afinamiento poderosa y fÃ¡cil de usar que se utiliza en muchos modelos de cÃ³digo abierto de vanguardia.
* [**DeepSpeed**](https://www.deepspeed.ai/): Pre-entrenamiento y afinamiento eficientes de LLMs para configuraciones multi-GPU y multi-nodo (implementado en Axolotl).

ğŸ“š **Referencias**:
* [GuÃ­a de entrenamiento de LLM para novatos](https://rentry.org/llm-training) por Alpin: VisiÃ³n general de los principales conceptos y parÃ¡metros a considerar al afinar LLMs.
* [Insights sobre LoRA](https://lightning.ai/pages/community/lora-insights/) por Sebastian Raschka: Perspectivas prÃ¡cticas sobre LoRA y cÃ³mo seleccionar los mejores parÃ¡metros.
* [Ajuste fino de tu propio modelo Llama-2](https://mlabonne.github.io/blog/posts/Fine_Tune_Your_Own_Llama_2_Model_in_a_Colab_Notebook.html): Tutorial prÃ¡ctico sobre cÃ³mo afinar un modelo Llama 2 usando bibliotecas de Hugging Face.
* [Padding de modelos de lenguaje grandes](https://towardsdatascience.com/padding-large-language-models-examples-with-llama-2-199fb10df8ff) por Benjamin Marie: Mejores prÃ¡cticas para rellenar ejemplos de entrenamiento para LLMs causales
* [Una GuÃ­a para principiantes en ajuste fino de LLMs](https://mlabonne.github.io/blog/posts/A_Beginners_Guide_to_LLM_Finetuning.html): Tutorial sobre cÃ³mo afinar un modelo CodeLlama usando Axolotl.

---
### Aprendizaje por refuerzo a partir de feedback humano (RLHF)

DespuÃ©s del afinamiento supervisado, el RLFH ("Reinforcement learning from human feedback") es un paso usado para alinear las respuestas del LLM con las expectativas humanas. La idea es aprender preferencias a partir de retroalimentaciÃ³n humana (o artificial), que se puede usar para reducir sesgos, censurar modelos, o hacerlos actuar de una manera mÃ¡s Ãºtil. Es mÃ¡s complejo que el SFT (supervised fine-tuning) y a menudo se ve como opcional.

* **Conjuntos de datos de preferencia**: Estos conjuntos tÃ­picamente contienen varias respuestas con algÃºn tipo de clasificaciÃ³n, lo que los hace mÃ¡s difÃ­ciles de producir que los conjuntos de instrucciones.
* [**OptimizaciÃ³n de polÃ­tica proxima**](https://arxiv.org/abs/1707.06347): Este algoritmo aprovecha un modelo de recompensa que predice si un texto dado estÃ¡ altamente clasificado por humanos. Esta predicciÃ³n se usa luego para optimizar el modelo SFT con una penalizaciÃ³n basada en divergencia KL.
* **[OptimizaciÃ³n de preferencia directa](https://arxiv.org/abs/2305.18290)**: DPO simplifica el proceso al reformularlo como un problema de clasificaciÃ³n. Usa un modelo de referencia en lugar de un modelo de recompensa (no necesita entrenamiento) y solo requiere un hiperparÃ¡metro, lo que lo hace mÃ¡s estable y eficiente.

ğŸ“š **Referencias**:
* [IntroducciÃ³n al entrenamiento de LLMs usando RLHF](https://wandb.ai/ayush-thakur/Intro-RLAIF/reports/An-Introduction-to-Training-LLMs-Using-Reinforcement-Learning-From-Human-Feedback-RLHF---VmlldzozMzYyNjcy) por Ayush Thakur: Explica por quÃ© el ARRH es deseable para reducir el sesgo y aumentar el rendimiento en LLMs.
* [IlustraciÃ³n RLHF](https://huggingface.co/blog/rlhf) por Hugging Face: IntroducciÃ³n al ARRH con entrenamiento de modelo de recompensa y afinamiento con aprendizaje por refuerzo.
* [StackLLaMA](https://huggingface.co/blog/stackllama) por Hugging Face: Tutorial para alinear eficientemente un modelo LLaMA con ARRH usando la biblioteca de transformers.
* [Entrenamiento de LLM: RLHF y sus alternativas](https://substack.com/profile/27393275-sebastian-raschka-phd) por Sebastian Rashcka: VisiÃ³n general del proceso de ARRH y alternativas como RLAIF.
* [Ajuste fino de Mistral-7b con DPO](https://huggingface.co/blog/dpo-trl): Tutorial para afinar un modelo Mistral-7b con DPO y reproducir [NeuralHermes-2.5](https://huggingface.co/mlabonne/NeuralHermes-2.5-Mistral-7B).

---
### EvaluaciÃ³n de modelos

Evaluar LLMs es una parte subestimada del pipeline, que consume tiempo y es moderadamente confiable. Tu tarea especÃ­fica deberÃ­a dictar quÃ© quieres evaluar, pero siempre recuerda la ley de Goodhart: "Cuando una medida se convierte en un objetivo, deja de ser una buena medida."

* **MÃ©tricas tradicionales**: MÃ©tricas como la perplejidad y el puntaje BLEU no son tan populares como lo eran porque estÃ¡n defectuosas en la mayorÃ­a de los contextos. AÃºn es importante entenderlas y cuÃ¡ndo pueden ser aplicadas.
* **Benchmarks generales**: Basados en el [Language Model Evaluation Harness](https://github.com/EleutherAI/lm-evaluation-harness), el [Open LLM Leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard) es el principal benchmark para LLMs de propÃ³sito general (como ChatGPT). Hay otros benchmarks populares como [BigBench](https://github.com/google/BIG-bench), [MT-Bench](https://arxiv.org/abs/2306.05685), etc.
* **Benchmarks especÃ­ficos de tareas**: Tareas como la summarizaciÃ³n, traducciÃ³n y respuesta a preguntas tienen benchmarks dedicados, mÃ©tricas e incluso subdominios (mÃ©dico, financiero, etc.), como [PubMedQA](https://pubmedqa.github.io/) para respuesta a preguntas biomÃ©dicas.
* **EvaluaciÃ³n humana**: La evaluaciÃ³n mÃ¡s confiable es la tasa de aceptaciÃ³n por parte de los usuarios o comparaciones hechas por humanos. Si quieres saber si un modelo rinde bien, la forma mÃ¡s simple pero segura es usarlo tÃº mismo.

ğŸ“š **Referencias**:
* [Perplejidad de modelos de longitud fija](https://huggingface.co/docs/transformers/perplexity) por Hugging Face: VisiÃ³n general de la perplejidad con cÃ³digo para implementarlo con la biblioteca de transformers.
* [BLEU a tu propio riesgo](https://towardsdatascience.com/evaluating-text-output-in-nlp-bleu-at-your-own-risk-e8609665a213) por Rachael Tatman: VisiÃ³n general del puntaje BLEU y sus muchos problemas con ejemplos.
* [Una encuesta sobre la evaluaciÃ³n de LLMs](https://arxiv.org/abs/2307.03109) por Chang et al.: Documento comprensivo sobre quÃ© evaluar, dÃ³nde evaluar y cÃ³mo evaluar.
* [Chatbot Arena Leaderboard](https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard) por lmsys: ClasificaciÃ³n Elo de LLMs de propÃ³sito general, basada en comparaciones hechas por humanos.

---
### CuantizaciÃ³n

La cuantizaciÃ³n es el proceso de convertir los pesos (y activaciones) de un modelo usando una precisiÃ³n menor. Por ejemplo, los pesos almacenados usando 16 bits pueden ser convertidos en una representaciÃ³n de 4 bits. Esta tÃ©cnica se ha vuelto cada vez mÃ¡s importante para reducir los costos computacionales y de memoria asociados con los LLMs.

* **TÃ©cnicas base**: Aprende los diferentes niveles de precisiÃ³n (FP32, FP16, INT8, etc.) y cÃ³mo realizar cuantizaciÃ³n naÃ­f con tÃ©cnicas de absmax y punto cero.
* **`GGUF` y `llama.cpp`**: Originalmente diseÃ±ado para correr en CPUs, [llama.cpp](https://github.com/ggerganov/llama.cpp) y el formato GGUF se han vuelto las herramientas mÃ¡s populares para correr LLMs en hardware de grado consumidor.
* **`GPTQ` y `EXL2`**: [GPTQ](https://arxiv.org/abs/2210.17323) y, mÃ¡s especÃ­ficamente, el formato [EXL2](https://github.com/turboderp/exllamav2) ofrecen una velocidad increÃ­ble pero solo pueden correr en GPUs. Los modelos tambiÃ©n toman un largo tiempo en ser cuantizados.
* **`AWQ`**: Este nuevo formato es mÃ¡s preciso que GPTQ (menor perplejidad) pero usa mucho mÃ¡s VRAM y no necesariamente es mÃ¡s rÃ¡pido.

ğŸ“š **Referencias**:
* [IntroducciÃ³n a la cuantizaciÃ³n](https://mlabonne.github.io/blog/posts/Introduction_to_Weight_Quantization.html): VisiÃ³n general de la cuantizaciÃ³n, cuantizaciÃ³n absmax y punto cero, y LLM.int8() con cÃ³digo.
* [Cuantiza modelos Llama con llama.cpp](https://mlabonne.github.io/blog/posts/Quantize_Llama_2_models_using_ggml.html): Tutorial sobre cÃ³mo cuantizar un modelo Llama 2 usando llama.cpp y el formato GGUF.
* [CuantizaciÃ³n de LLM de 4 bits con GPTQ](https://mlabonne.github.io/blog/posts/Introduction_to_Weight_Quantization.html): Tutorial sobre cÃ³mo cuantizar un LLM usando el algoritmo GPTQ con AutoGPTQ.
* [ExLlamaV2: La librerÃ­a mÃ¡s rÃ¡pida para correr LLMs](https://mlabonne.github.io/blog/posts/ExLlamaV2_The_Fastest_Library_to_Run%C2%A0LLMs.html): GuÃ­a sobre cÃ³mo cuantizar un modelo Mistral usando el formato EXL2 y correrlo con la biblioteca ExLlamaV2.
* [Entendiendo la cuantizaciÃ³n con AWQ](https://medium.com/friendliai/understanding-activation-aware-weight-quantization-awq-boosting-inference-serving-efficiency-in-10bb0faf63a8) por FriendliAI: VisiÃ³n general de la tÃ©cnica AWQ y sus beneficios.

---
### Nuevas tendencias

* **Codificaciones posicionales**: Aprende cÃ³mo los LLMs codifican posiciones, especialmente esquemas de codificaciÃ³n posicional relativa como [RoPE](https://arxiv.org/abs/2104.09864). Implementa [YaRN](https://arxiv.org/abs/2309.00071) (multiplica la matriz de atenciÃ³n por un factor de temperatura) o [ALiBi](https://arxiv.org/abs/2108.12409) (penalizaciÃ³n de atenciÃ³n basada en la distancia de tokens) para extender la longitud del contexto.
* **FusiÃ³n de modelos**: Fusionar modelos entrenados se ha vuelto una manera popular de crear modelos performantes sin ningÃºn afinamiento. La popular biblioteca [mergekit](https://github.com/cg123/mergekit) implementa los mÃ©todos de fusiÃ³n mÃ¡s populares, como SLERP, [DARE](https://arxiv.org/abs/2311.03099), y [TIES](https://arxiv.org/abs/2311.03099).
* **Mix de expertos**: [Mixtral](https://arxiv.org/abs/2401.04088) repopularizÃ³ la arquitectura MoE gracias a su excelente rendimiento. Paralelamente, un tipo de frankenMoE emergiÃ³ en la comunidad OSS fusionando modelos como [Phixtral](https://huggingface.co/mlabonne/phixtral-2x2_8), que es una opciÃ³n mÃ¡s econÃ³mica y performante.
* **Modelos multimodales**: Estos modelos (como [CLIP](https://openai.com/research/clip), [Stable Diffusion](https://stability.ai/stable-image), o [LLaVA](https://llava-vl.github.io/)) procesan mÃºltiples tipos de entradas (texto, imÃ¡genes, audio, etc.) con un espacio de incrustaciÃ³n unificado, lo que desbloquea aplicaciones poderosas como texto-a-imagen.

ğŸ“š **Referencias**:
* [Extendiendo el RoPE](https://blog.eleuther.ai/yarn/) por EleutherAI: ArtÃ­culo que resume las diferentes tÃ©cnicas de codificaciÃ³n de posiciÃ³n.
* [Entendiendo YaRN](https://medium.com/@rcrajatchawla/understanding-yarn-extending-context-window-of-llms-3f21e3522465) por Rajat Chawla: IntroducciÃ³n a YaRN.
* [Fusionar LLMs con `mergekit`](https://mlabonne.github.io/blog/posts/2024-01-08_Merge_LLMs_with_mergekit.html): Tutorial sobre fusiÃ³n de modelos usando mergekit.
* [Mix de expertos explicado](https://huggingface.co/blog/moe) por Hugging Face: GuÃ­a exhaustiva sobre MoEs y cÃ³mo funcionan.
* [Modelos multimodales grandes](https://huyenchip.com/2023/10/10/multimodal.html) por Chip Huyen: VisiÃ³n general de sistemas multimodales y la historia reciente de este campo.

## ğŸ‘· Roadmap para ser ingeniero/a de LLMs

Esta secciÃ³n del curso se enfoca en aprender cÃ³mo construir aplicaciones potenciadas por LLM que puedan usarse en producciÃ³n, con un enfoque en aumentar modelos y desplegarlos a escala.

```
ğŸ“
â”œâ”€â”€ ğŸš€ Corriendo LLMs
â”‚   â”œâ”€â”€ ğŸŒ APIs de LLM
â”‚   â”œâ”€â”€ ğŸ“– LLMs de cÃ³digo abierto
â”‚   â”œâ”€â”€ ğŸ’¡ IngenierÃ­a de prompts
â”‚   â””â”€â”€ ğŸ“ EstructuraciÃ³n de salidas
â”œâ”€â”€ ğŸ—‚ Creando bases de datos vectoriales
â”‚   â”œâ”€â”€ ğŸ“¥ Ingesta de documentos
â”‚   â”œâ”€â”€ âœ‚ï¸ DivisiÃ³n de documentos
â”‚   â”œâ”€â”€ ğŸ§¬ Modelos de embedding
â”‚   â””â”€â”€ ğŸ—ƒ Bases de datos vectoriales
â”œâ”€â”€ ğŸ¤– Retrieval augmented generation (generaciÃ³n aumentada por recuperaciÃ³n)
â”‚   â”œâ”€â”€ ğŸ› Orquestadores
â”‚   â”œâ”€â”€ ğŸ” Retrievers
â”‚   â”œâ”€â”€ ğŸ§  Memoria
â”‚   â””â”€â”€ ğŸ“‹ EvaluaciÃ³n
â”œâ”€â”€ âš™ï¸ RAG avanzado
â”‚   â”œâ”€â”€ ğŸ“ ConstrucciÃ³n de consultas
â”‚   â”œâ”€â”€ ğŸ›  Agentes y herramientas
â”‚   â””â”€â”€ ğŸ”„ Post-procesamiento
â”œâ”€â”€ ğŸš„ OptimizaciÃ³n de inferencia
â”‚   â”œâ”€â”€ âš¡ Flash attention
â”‚   â”œâ”€â”€ ğŸ— CachÃ© de key-value
â”‚   â””â”€â”€ ğŸ”® DecodificaciÃ³n especulativa
â”œâ”€â”€ ğŸ“¡ Desplegando LLMs
â”‚   â”œâ”€â”€ ğŸ  Despliegue local
â”‚   â”œâ”€â”€ ğŸ® Despliegue de un prototipo
â”‚   â”œâ”€â”€ ğŸ–¥ Despliegue en un servidor
â”‚   â””â”€â”€ ğŸŒ Despliegue en edge
â””â”€â”€ ğŸ”’ Asegurando LLMs
    â”œâ”€â”€ ğŸ£ Hacking de prompts
    â”œâ”€â”€ ğŸš§ Barreras de seguridad (guardrails)
    â”œâ”€â”€ ğŸšª Puertas traseras
    â””â”€â”€ ğŸ›¡ Medidas defensivas
```

### Corriendo LLMs

Ejecutar LLMs puede ser difÃ­cil debido a los altos requisitos de hardware. Dependiendo de tu caso de uso, podrÃ­as querer simplemente consumir un modelo a travÃ©s de una API (como `GPT-4`) o ejecutarlo localmente. En cualquier caso, tÃ©cnicas adicionales de prompting y alineamiento pueden mejorar y restringir los outputs para tus aplicaciones.

* **APIs de LLM**: Las APIs son una manera conveniente de desplegar LLMs. Este espacio estÃ¡ dividido entre LLMs privados o propietarios ([OpenAI](https://platform.openai.com/), [Google](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/overview), [Anthropic](https://docs.anthropic.com/claude/reference/getting-started-with-the-api), [Cohere](https://docs.cohere.com/docs), etc.) y LLMs de cÃ³digo abierto ([OpenRouter](https://openrouter.ai/), [Hugging Face](https://huggingface.co/inference-api), [Together AI](https://www.together.ai/), etc.).
* **LLMs de cÃ³digo abierto**: El [Hugging Face Hub](https://huggingface.co/models) es un excelente lugar para encontrar LLMs. Puedes ejecutar algunos de ellos directamente en [Hugging Face Spaces](https://huggingface.co/spaces), o descargarlos y ejecutarlos localmente en aplicaciones como [LM Studio](https://lmstudio.ai/) o a travÃ©s de la CLI con [llama.cpp](https://github.com/ggerganov/llama.cpp) o [Ollama](https://ollama.ai/).
* **IngenierÃ­a de prompts**: TÃ©cnicas comunes incluyen prompting de cero disparos, prompting de pocos disparos, cadena de pensamiento y ReAct. Funcionan mejor con modelos mÃ¡s grandes, pero pueden adaptarse a modelos mÃ¡s pequeÃ±os.
* **Estructurando outputs (resultados del modelo)**: Muchas tareas requieren un output estructurado, como una plantilla estricta o un formato `JSON`. LibrerÃ­as como [LMQL](https://lmql.ai/), [Outlines](https://github.com/outlines-dev/outlines), [Guidance](https://github.com/guidance-ai/guidance), etc. pueden usarse para guiar la generaciÃ³n y respetar una estructura dada.

ğŸ“š **Referencias**:
* [EjecutÃ¡ un LLM localmente con LM Studio](https://www.kdnuggets.com/run-an-llm-locally-with-lm-studio) por Nisha Arya: GuÃ­a corta sobre cÃ³mo usar LM Studio.
* [GuÃ­a de ingenierÃ­a de prompts](https://www.promptingguide.ai/) por DAIR.AI: Lista exhaustiva de tÃ©cnicas de prompts con ejemplos.
* [Outlines, Inicio rÃ¡pido](https://outlines-dev.github.io/outlines/quickstart/): Lista de tÃ©cnicas de generaciÃ³n guiada habilitadas por Outlines.
* [LMQL, ResÃºmen](https://lmql.ai/docs/language/overview.html): IntroducciÃ³n al lenguaje LMQL.

---
### Creando una base de datos vectorial

Crear un almacenamiento de vectores es el primer paso para construir un pipeline de **GeneraciÃ³n Aumentada por RecuperaciÃ³n** ("Retrieval Augmented Generation", RAG). Los documentos se ingestan, se dividen (split) y los fragmentos relevantes se usan para producir representaciones vectoriales (embeddings) que se almacenan para su uso futuro durante la inferencia.

* **Ingesta de documentos**: Los cargadores de documentos son wrappers convenientes que pueden manejar muchos formatos: `PDF`, `JSON`, `HTML`, `Markdown`, etc. TambiÃ©n pueden traer datos directamente de algunas bases de datos y APIs (GitHub, Reddit, Google Drive, etc.).
* **DivisiÃ³n de documentos**: Los divisores de texto descomponen los documentos en fragmentos mÃ¡s pequeÃ±os, semÃ¡nticamente significativos. En lugar de dividir el texto despuÃ©s de *n* caracteres, a menudo es mejor dividir por encabezado o recursivamente, con algunos metadatos adicionales.
* **Modelos de embeddings**: Los modelos de embeddings convierten el texto en representaciones vectoriales. Permite una comprensiÃ³n mÃ¡s profunda y matizada del lenguaje, esencial para realizar bÃºsquedas semÃ¡nticas.
* **Bases de datos vectoriales**: Las bases de datos vectoriales (como [Chroma](https://www.trychroma.com/), [Pinecone](https://www.pinecone.io/), [Milvus](https://milvus.io/), [FAISS](https://faiss.ai/), [Annoy](https://github.com/spotify/annoy), etc.) estÃ¡n diseÃ±adas para almacenar vectores de embeddings. Nos permiten traer, de forma eficiente, informaciÃ³n quÃ© es "mÃ¡s similar" a una consulta hecha al modelo basado en la similitud que tenemos entre vectores.

ğŸ“š **Referencias**:
* [LangChain, divisores de texto](https://python.langchain.com/docs/modules/data_connection/document_transformers/): Lista de diferentes divisores de texto implementados en LangChain.
* [LibrerÃ­a de SentenceTransformers](https://www.sbert.net/): Biblioteca popular para modelos de embeddings.
* [MTEB leaderboard](https://huggingface.co/spaces/mteb/leaderboard): Leaderboard para modelos de embeddings.
* [Las 5 Mejores Bases de Datos Vectoriales](https://www.datacamp.com/blog/the-top-5-vector-databases) por Moez Ali: Una comparaciÃ³n de las mejores y mÃ¡s populares bases de datos vectoriales.

---
### GeneraciÃ³n aumentada por recuperaciÃ³n (RAG)

Con RAG, los LLMs recuperan documentos contextuales de una base de datos para mejorar la precisiÃ³n de sus respuestas. RAG es una forma popular de aumentar el conocimiento del modelo sin necesidad de afinamiento adicional.

* **Orquestadores**: Los orquestadores (como [LangChain](https://python.langchain.com/docs/get_started/introduction), [LlamaIndex](https://docs.llamaindex.ai/en/stable/), [FastRAG](https://github.com/IntelLabs/fastRAG), etc.) son marcos populares para conectar tus LLMs con herramientas, bases de datos, memorias, etc., y aumentar sus habilidades.
* **Recuperadores**: Las instrucciones de los usuarios no estÃ¡n optimizadas para la recuperaciÃ³n. Diferentes tÃ©cnicas (por ejemplo, recuperador de mÃºltiples consultas, [HyDE](https://arxiv.org/abs/2212.10496), etc.) pueden aplicarse para reformular/ampliarlas y mejorar el rendimiento.
* **Memoria**: Para recordar instrucciones y respuestas anteriores, LLMs y chatbots como ChatGPT agregan este historial a su ventana de contexto. Este bÃºfer puede mejorarse con resÃºmenes (por ejemplo, usando un LLM mÃ¡s pequeÃ±o), una tienda vectorial + RAG, etc.
* **EvaluaciÃ³n**: Necesitamos evaluar tanto la recuperaciÃ³n de documentos (precisiÃ³n y recall del contexto) como las etapas de generaciÃ³n (fidelidad y relevancia de la respuesta). Se puede simplificar con herramientas como [Ragas](https://github.com/explodinggradients/ragas/tree/main) y [DeepEval](https://github.com/confident-ai/deepeval).

ğŸ“š **Referencias**:
* [Llamaindex, conceptos de alto nivel](https://docs.llamaindex.ai/en/stable/getting_started/concepts.html): Conceptos principales a conocer al construir tuberÃ­as RAG.
* [Pinecone, aumento de recuperaciÃ³n](https://www.pinecone.io/learn/series/langchain/langchain-retrieval-augmentation/): VisiÃ³n general del proceso de augmentaciÃ³n de recuperaciÃ³n.
* [LangChain, Q&A con RAG](https://python.langchain.com/docs/use_cases/question_answering/quickstart): Tutorial paso a paso para construir una tÃ­pica tuberÃ­a RAG.
* [LangChain, tipos de memoria](https://python.langchain.com/docs/modules/memory/types/): Lista de diferentes tipos de memorias con usos relevantes.
* [Pipeline RAG, mÃ©tricas](https://docs.ragas.io/en/stable/concepts/metrics/index.html): ResÃºmen general de las principales mÃ©tricas utilizadas para evaluar pipeline RAG.

---
### RAG Avanzado

Aplicaciones en producciÃ³n pueden requerir pipelines complejos, incluyendo bases de datos SQL o de grafos, asÃ­ como la selecciÃ³n automÃ¡tica de herramientas y APIs relevantes. Estas tÃ©cnicas avanzadas pueden mejorar una soluciÃ³n base y proporcionar caracterÃ­sticas adicionales.

* **ConstrucciÃ³n de consultas/queries**: Los datos estructurados almacenados en bases de datos tradicionales requieren un lenguaje de consulta especÃ­fico como SQL, Cypher, metadatos, etc. Podemos traducir directamente la instrucciÃ³n del usuario en una consulta para acceder a los datos con la construcciÃ³n de consultas.
* **Agentes y herramientas**: Los agentes aumentan los LLMs seleccionando automÃ¡ticamente las herramientas mÃ¡s relevantes para proporcionar una respuesta. Estas herramientas pueden ser tan simples como usar Google o Wikipedia, o mÃ¡s complejas como un intÃ©rprete de Python o Jira.
* **Post-procesamiento**: Paso final que procesa las entradas que se alimentan al LLM. Mejora la relevancia y diversidad de los documentos recuperados con reordenamiento, [RAG-fusiÃ³n](https://github.com/Raudaschl/rag-fusion), y clasificaciÃ³n.

ğŸ“š **Referencias**:
* [LangChain, construcciÃ³n de consultas/queries](https://blog.langchain.dev/query-construction/): Posteo sobre diferentes tipos de construcciÃ³n de consultas.
* [LangChain, SQL](https://python.langchain.com/docs/use_cases/qa_structured/sql): Tutorial sobre cÃ³mo interactuar con bases de datos SQL con LLMs, involucrando Texto-a-SQL y un agente SQL opcional.
* [Pinecone, agentes LLM](https://www.pinecone.io/learn/series/langchain/langchain-agents/): IntroducciÃ³n a agentes y herramientas con diferentes tipos.
* [Agentes autÃ³nomos potenciados por LLM](https://lilianweng.github.io/posts/2023-06-23-agent/) por Lilian Weng: ArtÃ­culo mÃ¡s teÃ³rico sobre agentes LLM.
* [LangChain, RAG de OpenAI](https://blog.langchain.dev/applying-openai-rag/): VisiÃ³n general de las estrategias RAG empleadas por OpenAI, incluyendo post-procesamiento.

---
### OptimizaciÃ³n de la inferencia de un modelo

La generaciÃ³n de texto es un proceso costoso que requiere hardware caro. AdemÃ¡s de la cuantizaciÃ³n, se han propuesto varias tÃ©cnicas para maximizar el rendimiento y reducir los costos de inferencia.

* **Flash attention**: OptimizaciÃ³n del mecanismo de atenciÃ³n para transformar su complejidad de cuadrÃ¡tica a lineal, acelerando tanto el entrenamiento como la inferencia.
* **CachÃ© de key-value**: Entiende el cachÃ© de key-value y las mejoras introducidas en la [atenciÃ³n de mÃºltiples consultas](https://arxiv.org/abs/1911.02150) (MQA) y la [atenciÃ³n de consultas agrupadas](https://arxiv.org/abs/2305.13245) (GQA).
* **DecodificaciÃ³n especulativa**: Usa un modelo pequeÃ±o para producir borradores que luego son revisados por un modelo mÃ¡s grande para acelerar la generaciÃ³n de texto.

ğŸ“š **Referencias**:
* [Inferencia en GPU](https://huggingface.co/docs/transformers/main/en/perf_infer_gpu_one) por Hugging Face: Explica cÃ³mo optimizar la inferencia en GPUs.
* [Inferencia de LLM](https://www.databricks.com/blog/llm-inference-performance-engineering-best-practices) por Databricks: Mejores prÃ¡cticas sobre cÃ³mo optimizar la inferencia de LLM en producciÃ³n.
* [Optimizando LLMs para velocidad y memoria](https://huggingface.co/docs/transformers/main/en/llm_tutorial_optimization) por Hugging Face: Explica tres tÃ©cnicas principales para optimizar velocidad y memoria, a saber, cuantizaciÃ³n, AtenciÃ³n Flash e innovaciones arquitectÃ³nicas.
* [GeneraciÃ³n asistida](https://huggingface.co/blog/assisted-generation) por Hugging Face: VersiÃ³n de Hugging Face de la decodificaciÃ³n especulativa, es un post interesante sobre cÃ³mo funciona con cÃ³digo para implementarlo.

---
### Desplegando LLMs

Desplegar LLMs a escala es una hazaÃ±a de ingenierÃ­a que puede requerir mÃºltiples clÃºsteres de GPUs. En otros escenarios, demos y aplicaciones locales pueden lograrse con mucha menor complejidad.

* **Despliegue local**: La privacidad es una ventaja importante que los LLMs de cÃ³digo abierto tienen sobre los privados. Servidores LLM locales ([LM Studio](https://lmstudio.ai/), [Ollama](https://ollama.ai/), [oobabooga](https://github.com/oobabooga/text-generation-webui), [kobold.cpp](https://github.com/LostRuins/koboldcpp), etc.) capitalizan esta ventaja para potenciar aplicaciones locales.
* **Despliegue de un prototipo**: Frameworks como [Gradio](https://www.gradio.app/) y [Streamlit](https://docs.streamlit.io/) son Ãºtiles para prototipar aplicaciones y compartir demos. TambiÃ©n puedes alojarlos fÃ¡cilmente en lÃ­nea, por ejemplo, usando [Hugging Face Spaces](https://huggingface.co/spaces).
* **Despliegue en un servidor**: Desplegar LLMs a escala requiere infraestructura en la nube (ver tambiÃ©n [SkyPilot](https://skypilot.readthedocs.io/en/latest/)) o local y a menudo aprovecha frameworks de generaciÃ³n de texto optimizados como [TGI](https://github.com/huggingface/text-generation-inference), [vLLM](https://github.com/vllm-project/vllm/tree/main), etc.
* **Despliegue en el edge**: En entornos restringidos, frameworks de alto rendimiento como [MLC LLM](https://github.com/mlc-ai/mlc-llm) y [mnn-llm](https://github.com/wangzhaode/mnn-llm/blob/master/README_en.md) pueden desplegar LLMs en navegadores web, Android, e iOS.

ğŸ“š **Referencias**:
* [Streamlit, construye una aplicaciÃ³n LLM bÃ¡sica](https://docs.streamlit.io/knowledge-base/tutorials/build-conversational-apps): Tutorial para hacer una app bÃ¡sica tipo ChatGPT usando Streamlit.
* [Contenedor Docker de inferencia LLM de HF](https://huggingface.co/blog/sagemaker-huggingface-llm): Despliega LLMs en Amazon SageMaker usando el contenedor de inferencia de Hugging Face.
* [Blog](https://www.philschmid.de/) por Philipp Schmid: ColecciÃ³n de artÃ­culos de alta calidad sobre despliegue y ajuste fino de LLMs.
* [Optimizando la latencia](https://hamel.dev/notes/llm/inference/03_inference.html) por Hamel Husain: ComparaciÃ³n de TGI, vLLM, CTranslate2 y mlc en tÃ©rminos de rendimiento y latencia.

---
### Haciendo a los LLMs mas seguros

AdemÃ¡s de los problemas de seguridad tradicionales asociados con el software, los LLMs tienen debilidades Ãºnicas debido a la forma en que son entrenados y consultados.

* **Hackeo de prompts**: Diferentes tÃ©cnicas relacionadas con la ingenierÃ­a de prompts, incluyendo inyecciÃ³n de prompts (instrucciÃ³n adicional para modificar la respuesta del modelo), filtraciÃ³n de datos/prompts (recuperar sus datos/prompts originales), y jailbreaking (crear prompts para eludir caracterÃ­sticas de seguridad).
* **Puertas traseras**: Los vectores de ataque pueden apuntar al propio conjunto de datos de entrenamiento, envenenando los datos de entrenamiento (por ejemplo, con informaciÃ³n falsa) o creando puertas traseras (disparadores secretos para cambiar el comportamiento del modelo durante la inferencia).
* **Medidas defensivas**: La mejor manera de proteger tus aplicaciones LLM es probarlas contra estas vulnerabilidades (por ejemplo, usando equipos rojos y controles como [garak](https://github.com/leondz/garak/)) y observarlas en producciÃ³n (con un marco como [langfuse](https://github.com/langfuse/langfuse)).

ğŸ“š **Referencias**:
* [OWASP Top 10 para aplicaciones de LLM](https://owasp.org/www-project-top-10-for-large-language-model-applications/) por HEGO Wiki: Lista de las 10 vulnerabilidades crÃ­ticas mÃ¡s vistas en aplicaciones LLM.
* [InyecciÃ³n de prompts](https://github.com/jthack/PIPE) por Joseph Thacker: GuÃ­a corta dedicada a la inyecciÃ³n de prompts para ingenieros.
* [Seguridad en LLMs](https://llmsecurity.net/) por [@llm_sec](https://twitter.com/llm_sec): Lista extensiva de recursos relacionados con la seguridad LLM.
* [Equipos rojos (red teaming) en LLMs](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/red-teaming) por Microsoft: GuÃ­a sobre cÃ³mo realizar equipos rojos con LLMs.

---
## Reconocimientos

Este roadmap estÃ¡ inspirado fuertemente (robado) del roadmap que hizo Maxime Labonne ([twitter](https://twitter.com/maximelabonne) & [github](https://github.com/mlabonne))

*Disclaimer: No estoy afiliado con ninguna instituciÃ³n mencionada acÃ¡.*

---
<p align="center">
  <a href="https://star-history.com/#machinelearnear/curso-ia-generativa-y-llms&Date">
    <img src="https://api.star-history.com/svg?repos=machinelearnear/curso-ia-generativa-y-llms&type=Date" alt="Star History Chart">
  </a>
</p>
